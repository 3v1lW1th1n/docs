<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>RUNDECK(1) RunDeck User Manuals | Version 1.0</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Alex Honor" />
  <meta name="date" content="November 20, 2010" />
  <link rel="stylesheet" href="RunDeck-Guide.css" type="text/css" />
</head>
<body>
<h1 class="title">RUNDECK(1) RunDeck User Manuals | Version 1.0</h1>
<div id="TOC"
><ul
  ><li
    ><a href="#introduction"
      ><span class="toc-section-number"
	>1</span
	> Introduction</a
      ><ul
      ><li
	><a href="#what-is-this-guide-about"
	  ><span class="toc-section-number"
	    >1.1</span
	    > What is this guide about?</a
	  ><ul
	  ><li
	    ><a href="#who-makes-the-rundeck-software"
	      ><span class="toc-section-number"
		>1.1.1</span
		> Who makes the RunDeck software?</a
	      ></li
	    ><li
	    ><a href="#why-is-rundeck-open-source"
	      ><span class="toc-section-number"
		>1.1.2</span
		> Why is RunDeck open source?</a
	      ></li
	    ><li
	    ><a href="#why-is-it-called-rundeck"
	      ><span class="toc-section-number"
		>1.1.3</span
		> Why is it called RunDeck</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#rundeck-from-30000-feet"
	  ><span class="toc-section-number"
	    >1.2</span
	    > RunDeck from 30,000 feet</a
	  ><ul
	  ><li
	    ><a href="#rundeck-in-the-tool-chain"
	      ><span class="toc-section-number"
		>1.2.1</span
		> RunDeck in the tool chain</a
	      ></li
	    ><li
	    ><a href="#rundeck-architecture"
	      ><span class="toc-section-number"
		>1.2.2</span
		> RunDeck architecture</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#getting-help"
	  ><span class="toc-section-number"
	    >1.3</span
	    > Getting help</a
	  ></li
	><li
	><a href="#whats-next"
	  ><span class="toc-section-number"
	    >1.4</span
	    > What's next?</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#getting-started"
      ><span class="toc-section-number"
	>2</span
	> Getting Started</a
      ><ul
      ><li
	><a href="#rundeck-basics"
	  ><span class="toc-section-number"
	    >2.1</span
	    > RunDeck Basics</a
	  ><ul
	  ><li
	    ><a href="#command-dispatching"
	      ><span class="toc-section-number"
		>2.1.1</span
		> Command dispatching</a
	      ></li
	    ><li
	    ><a href="#resource-model"
	      ><span class="toc-section-number"
		>2.1.2</span
		> Resource model</a
	      ></li
	    ><li
	    ><a href="#authorization"
	      ><span class="toc-section-number"
		>2.1.3</span
		> Authorization</a
	      ></li
	    ><li
	    ><a href="#project"
	      ><span class="toc-section-number"
		>2.1.4</span
		> Project</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#installing-rundeck"
	  ><span class="toc-section-number"
	    >2.2</span
	    > Installing RunDeck</a
	  ><ul
	  ><li
	    ><a href="#system-requirements"
	      ><span class="toc-section-number"
		>2.2.1</span
		> System Requirements</a
	      ><ul
	      ><li
		><a href="#java"
		  ><span class="toc-section-number"
		    >2.2.1.1</span
		    > Java</a
		  ></li
		><li
		><a href="#network-access"
		  ><span class="toc-section-number"
		    >2.2.1.2</span
		    > Network access</a
		  ></li
		></ul
	      ></li
	    ><li
	    ><a href="#installing-from-source"
	      ><span class="toc-section-number"
		>2.2.2</span
		> Installing from Source</a
	      ></li
	    ><li
	    ><a href="#installing-on-linux"
	      ><span class="toc-section-number"
		>2.2.3</span
		> Installing on Linux</a
	      ></li
	    ><li
	    ><a href="#installing-on-other-platforms"
	      ><span class="toc-section-number"
		>2.2.4</span
		> Installing on other platforms</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#first-time-setup"
	  ><span class="toc-section-number"
	    >2.3</span
	    > First-Time Setup</a
	  ><ul
	  ><li
	    ><a href="#logins"
	      ><span class="toc-section-number"
		>2.3.1</span
		> Logins</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#summary"
	  ><span class="toc-section-number"
	    >2.4</span
	    > Summary</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#rundeck-basics-1"
      ><span class="toc-section-number"
	>3</span
	> RunDeck Basics</a
      ><ul
      ><li
	><a href="#rundeck-interfaces"
	  ><span class="toc-section-number"
	    >3.1</span
	    > RunDeck Interfaces</a
	  ><ul
	  ><li
	    ><a href="#graphical-console"
	      ><span class="toc-section-number"
		>3.1.1</span
		> Graphical Console</a
	      ><ul
	      ><li
		><a href="#navigation"
		  ><span class="toc-section-number"
		    >3.1.1.1</span
		    > Navigation</a
		  ></li
		></ul
	      ></li
	    ><li
	    ><a href="#shell-tools"
	      ><span class="toc-section-number"
		>3.1.2</span
		> Shell Tools</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#project-setup"
	  ><span class="toc-section-number"
	    >3.2</span
	    > Project Setup</a
	  ><ul
	  ><li
	    ><a href="#resource-model-1"
	      ><span class="toc-section-number"
		>3.2.1</span
		> Resource model</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#command-execution"
	  ><span class="toc-section-number"
	    >3.3</span
	    > Command Execution</a
	  ><ul
	  ><li
	    ><a href="#dispatcher-options"
	      ><span class="toc-section-number"
		>3.3.1</span
		> Dispatcher options</a
	      ><ul
	      ><li
		><a href="#filtering-nodes-graphically"
		  ><span class="toc-section-number"
		    >3.3.1.1</span
		    > Filtering nodes graphically</a
		  ></li
		><li
		><a href="#filtering-nodes-in-the-shell"
		  ><span class="toc-section-number"
		    >3.3.1.2</span
		    > Filtering nodes in the shell</a
		  ></li
		></ul
	      ></li
	    ><li
	    ><a href="#ad-hoc-commands"
	      ><span class="toc-section-number"
		>3.3.2</span
		> Ad-hoc commands</a
	      ><ul
	      ><li
		><a href="#shell-tool-command-execution"
		  ><span class="toc-section-number"
		    >3.3.2.1</span
		    > Shell tool command execution</a
		  ></li
		><li
		><a href="#graphical-command-shell-execution"
		  ><span class="toc-section-number"
		    >3.3.2.2</span
		    > Graphical command shell execution</a
		  ><ul
		  ><li
		    ><a href="#following-execution-output"
		      ><span class="toc-section-number"
			>3.3.2.2.1</span
			> Following execution output</a
		      ></li
		    ></ul
		  ></li
		></ul
	      ></li
	    ><li
	    ><a href="#controlling-ad-hoc-command-execution"
	      ><span class="toc-section-number"
		>3.3.3</span
		> Controlling ad-hoc command execution</a
	      ></li
	    ><li
	    ><a href="#queuing-commands-to-rundeck"
	      ><span class="toc-section-number"
		>3.3.4</span
		> Queuing commands to RunDeck</a
	      ></li
	    ><li
	    ><a href="#tracking-execution"
	      ><span class="toc-section-number"
		>3.3.5</span
		> Tracking execution</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#history"
	  ><span class="toc-section-number"
	    >3.4</span
	    > History</a
	  ><ul
	  ><li
	    ><a href="#filtering-event-history"
	      ><span class="toc-section-number"
		>3.4.1</span
		> Filtering event history</a
	      ></li
	    ><li
	    ><a href="#event-view"
	      ><span class="toc-section-number"
		>3.4.2</span
		> Event view</a
	      ></li
	    ><li
	    ><a href="#rss-link"
	      ><span class="toc-section-number"
		>3.4.3</span
		> RSS Link</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#tips-and-tricks"
	  ><span class="toc-section-number"
	    >3.5</span
	    > Tips and Tricks</a
	  ><ul
	  ><li
	    ><a href="#saving-filters"
	      ><span class="toc-section-number"
		>3.5.1</span
		> Saving filters</a
	      ></li
	    ><li
	    ><a href="#auto-completion"
	      ><span class="toc-section-number"
		>3.5.2</span
		> Auto-Completion</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#summary-1"
	  ><span class="toc-section-number"
	    >3.6</span
	    > Summary</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#jobs"
      ><span class="toc-section-number"
	>4</span
	> Jobs</a
      ><ul
      ><li
	><a href="#job-groups"
	  ><span class="toc-section-number"
	    >4.1</span
	    > Job groups</a
	  ></li
	><li
	><a href="#listing-and-filtering-jobs"
	  ><span class="toc-section-number"
	    >4.2</span
	    > Listing and filtering Jobs</a
	  ><ul
	  ><li
	    ><a href="#filtering-jobs"
	      ><span class="toc-section-number"
		>4.2.1</span
		> Filtering Jobs</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#running-a-job"
	  ><span class="toc-section-number"
	    >4.3</span
	    > Running a Job</a
	  ><ul
	  ><li
	    ><a href="#choose-execution-options"
	      ><span class="toc-section-number"
		>4.3.1</span
		> Choose execution options</a
	      ></li
	    ><li
	    ><a href="#following-running-jobs"
	      ><span class="toc-section-number"
		>4.3.2</span
		> Following Running Jobs</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#creating-jobs"
	  ><span class="toc-section-number"
	    >4.4</span
	    > Creating Jobs</a
	  ><ul
	  ><li
	    ><a href="#temporary-jobs"
	      ><span class="toc-section-number"
		>4.4.1</span
		> Temporary Jobs</a
	      ></li
	    ><li
	    ><a href="#saved-jobs"
	      ><span class="toc-section-number"
		>4.4.2</span
		> Saved Jobs</a
	      ></li
	    ><li
	    ><a href="#simple-saved-job"
	      ><span class="toc-section-number"
		>4.4.3</span
		> Simple saved job</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#scheduled-jobs"
	  ><span class="toc-section-number"
	    >4.5</span
	    > Scheduled Jobs</a
	  ></li
	><li
	><a href="#job-history"
	  ><span class="toc-section-number"
	    >4.6</span
	    > Job history</a
	  ></li
	><li
	><a href="#killing-jobs"
	  ><span class="toc-section-number"
	    >4.7</span
	    > Killing Jobs</a
	  ></li
	><li
	><a href="#deleting-jobs"
	  ><span class="toc-section-number"
	    >4.8</span
	    > Deleting Jobs</a
	  ></li
	><li
	><a href="#updating-and-copying-jobs"
	  ><span class="toc-section-number"
	    >4.9</span
	    > Updating and copying Jobs</a
	  ></li
	><li
	><a href="#exporting-jobs-as-xml"
	  ><span class="toc-section-number"
	    >4.10</span
	    > Exporting Jobs as XML</a
	  ></li
	><li
	><a href="#importing-jobs-as-xml"
	  ><span class="toc-section-number"
	    >4.11</span
	    > Importing Jobs as XML</a
	  ></li
	><li
	><a href="#summary-2"
	  ><span class="toc-section-number"
	    >4.12</span
	    > Summary</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#job-workflows"
      ><span class="toc-section-number"
	>5</span
	> Job Workflows</a
      ><ul
      ><li
	><a href="#authoring-tools"
	  ><span class="toc-section-number"
	    >5.1</span
	    > Authoring tools</a
	  ></li
	><li
	><a href="#workflow-control-settings"
	  ><span class="toc-section-number"
	    >5.2</span
	    > Workflow control settings</a
	  ></li
	><li
	><a href="#workflow-steps"
	  ><span class="toc-section-number"
	    >5.3</span
	    > Workflow steps</a
	  ><ul
	  ><li
	    ><a href="#command-step"
	      ><span class="toc-section-number"
		>5.3.1</span
		> Command step</a
	      ></li
	    ><li
	    ><a href="#script-step"
	      ><span class="toc-section-number"
		>5.3.2</span
		> Script step</a
	      ></li
	    ><li
	    ><a href="#script-file-step"
	      ><span class="toc-section-number"
		>5.3.3</span
		> Script file step</a
	      ></li
	    ><li
	    ><a href="#job-reference-step"
	      ><span class="toc-section-number"
		>5.3.4</span
		> Job reference step</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#reordering-steps"
	  ><span class="toc-section-number"
	    >5.4</span
	    > Reordering steps</a
	  ></li
	><li
	><a href="#save-the-changes"
	  ><span class="toc-section-number"
	    >5.5</span
	    > Save the changes</a
	  ></li
	><li
	><a href="#summary-3"
	  ><span class="toc-section-number"
	    >5.6</span
	    > Summary</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#job-options"
      ><span class="toc-section-number"
	>6</span
	> Job Options</a
      ><ul
      ><li
	><a href="#prompting-the-user"
	  ><span class="toc-section-number"
	    >6.1</span
	    > Prompting the user</a
	  ></li
	><li
	><a href="#options-editor"
	  ><span class="toc-section-number"
	    >6.2</span
	    > Options editor</a
	  ></li
	><li
	><a href="#defining-an-option"
	  ><span class="toc-section-number"
	    >6.3</span
	    > Defining an option</a
	  ></li
	><li
	><a href="#option-valuesurl"
	  ><span class="toc-section-number"
	    >6.4</span
	    > Option valuesUrl</a
	  ><ul
	  ><li
	    ><a href="#json-format"
	      ><span class="toc-section-number"
		>6.4.1</span
		> JSON format</a
	      ></li
	    ><li
	    ><a href="#variable-expansion-in-remote-urls"
	      ><span class="toc-section-number"
		>6.4.2</span
		> Variable expansion in remote URLs</a
	      ></li
	    ><li
	    ><a href="#remote-request-failures"
	      ><span class="toc-section-number"
		>6.4.3</span
		> Remote request failures</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#script-usage"
	  ><span class="toc-section-number"
	    >6.5</span
	    > Script usage</a
	  ></li
	><li
	><a href="#calling-a-job-with-options"
	  ><span class="toc-section-number"
	    >6.6</span
	    > Calling a Job with options</a
	  ></li
	><li
	><a href="#summary-4"
	  ><span class="toc-section-number"
	    >6.7</span
	    > Summary</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#authorization-1"
      ><span class="toc-section-number"
	>7</span
	> Authorization</a
      ><ul
      ><li
	><a href="#summary-5"
	  ><span class="toc-section-number"
	    >7.1</span
	    > Summary</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#rundeck-by-example"
      ><span class="toc-section-number"
	>8</span
	> RunDeck by example</a
      ><ul
      ><li
	><a href="#acme-anvils"
	  ><span class="toc-section-number"
	    >8.1</span
	    > Acme Anvils</a
	  ></li
	><li
	><a href="#rundeck-set-up"
	  ><span class="toc-section-number"
	    >8.2</span
	    > RunDeck set up</a
	  ></li
	><li
	><a href="#tag-classification-and-command-dispatching"
	  ><span class="toc-section-number"
	    >8.3</span
	    > Tag classification and command dispatching</a
	  ></li
	><li
	><a href="#jobs-1"
	  ><span class="toc-section-number"
	    >8.4</span
	    > Jobs</a
	  ><ul
	  ><li
	    ><a href="#job-structure"
	      ><span class="toc-section-number"
		>8.4.1</span
		> Job structure</a
	      ></li
	    ><li
	    ><a href="#job-grouping"
	      ><span class="toc-section-number"
		>8.4.2</span
		> Job grouping</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#job-option"
	  ><span class="toc-section-number"
	    >8.5</span
	    > Job option</a
	  ><ul
	  ><li
	    ><a href="#allowed-values"
	      ><span class="toc-section-number"
		>8.5.1</span
		> Allowed values</a
	      ></li
	    ><li
	    ><a href="#script-access-to-option-data"
	      ><span class="toc-section-number"
		>8.5.2</span
		> Script access to option data</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#job-workflow-composition"
	  ><span class="toc-section-number"
	    >8.6</span
	    > Job workflow composition</a
	  ></li
	><li
	><a href="#running-the-job"
	  ><span class="toc-section-number"
	    >8.7</span
	    > Running the job</a
	  ></li
	><li
	><a href="#job-access-control"
	  ><span class="toc-section-number"
	    >8.8</span
	    > Job access control</a
	  ></li
	><li
	><a href="#resource-model-provider"
	  ><span class="toc-section-number"
	    >8.9</span
	    > Resource model provider</a
	  ><ul
	  ><li
	    ><a href="#simple-scm-resource-model-provider"
	      ><span class="toc-section-number"
		>8.9.1</span
		> Simple SCM resource model provider</a
	      ></li
	    ><li
	    ><a href="#editable-resource-model-providers"
	      ><span class="toc-section-number"
		>8.9.2</span
		> Editable resource model providers</a
	      ><ul
	      ><li
		><a href="#rightscale-resource-model-provider"
		  ><span class="toc-section-number"
		    >8.9.2.1</span
		    > RightScale resource model provider</a
		  ></li
		><li
		><a href="#custom-database-resource-model-provider"
		  ><span class="toc-section-number"
		    >8.9.2.2</span
		    > Custom database resource model provider</a
		  ></li
		></ul
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#option-model-provider"
	  ><span class="toc-section-number"
	    >8.10</span
	    > Option model provider</a
	  ><ul
	  ><li
	    ><a href="#hudson-artifacts-option-provider"
	      ><span class="toc-section-number"
		>8.10.1</span
		> Hudson artifacts option provider</a
	      ></li
	    ><li
	    ><a href="#yum-repoquery-option-model-provider"
	      ><span class="toc-section-number"
		>8.10.2</span
		> Yum repoquery option model provider</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#summary-6"
	  ><span class="toc-section-number"
	    >8.11</span
	    > Summary</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#coordinatation"
      ><span class="toc-section-number"
	>9</span
	> Coordinatation</a
      ><ul
      ><li
	><a href="#execution-strategies-revisited"
	  ><span class="toc-section-number"
	    >9.1</span
	    > Execution strategies revisited</a
	  ><ul
	  ><li
	    ><a href="#step-vs-node-oriented"
	      ><span class="toc-section-number"
		>9.1.1</span
		> Step vs Node oriented</a
	      ></li
	    ><li
	    ><a href="#topology-structures-tiers-and-slices"
	      ><span class="toc-section-number"
		>9.1.2</span
		> Topology structures: Tiers and Slices</a
	      ></li
	    ><li
	    ><a href="#coordination-models"
	      ><span class="toc-section-number"
		>9.1.3</span
		> Coordination models</a
	      ><ul
	      ><li
		><a href="#sync-points"
		  ><span class="toc-section-number"
		    >9.1.3.1</span
		    > Sync points</a
		  ></li
		></ul
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#summary-7"
	  ><span class="toc-section-number"
	    >9.2</span
	    > Summary</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#administration"
      ><span class="toc-section-number"
	>10</span
	> Administration</a
      ><ul
      ><li
	><a href="#ssl"
	  ><span class="toc-section-number"
	    >10.1</span
	    > SSL</a
	  ></li
	><li
	><a href="#ldap"
	  ><span class="toc-section-number"
	    >10.2</span
	    > LDAP</a
	  ></li
	><li
	><a href="#backup-and-recovery"
	  ><span class="toc-section-number"
	    >10.3</span
	    > Backup and recovery</a
	  ></li
	><li
	><a href="#high-availability"
	  ><span class="toc-section-number"
	    >10.4</span
	    > High availability</a
	  ></li
	><li
	><a href="#configuration"
	  ><span class="toc-section-number"
	    >10.5</span
	    > Configuration</a
	  ></li
	><li
	><a href="#logs"
	  ><span class="toc-section-number"
	    >10.6</span
	    > Logs</a
	  ></li
	><li
	><a href="#summary-8"
	  ><span class="toc-section-number"
	    >10.7</span
	    > Summary</a
	  ></li
	></ul
      ></li
    ></ul
  ></div
>
<h1 id="introduction"
><a href="#TOC"
  ><span class="header-section-number"
    >1</span
    > Introduction</a
  ></h1
><h2 id="what-is-this-guide-about"
><a href="#TOC"
  ><span class="header-section-number"
    >1.1</span
    > What is this guide about?</a
  ></h2
><p
>Welcome to the RunDeck user guide. This guide was written to help administrators quickly become productive with the RunDeck server.</p
><p
>RunDeck is open source software that helps administrators automate ad-hoc and routine procedures. RunDeck provides a number of features that help you scale your scripting in a distributed environment for multi-step procedures. RunDeck helps alleviate time-consuming grunt work that comes from managing many systems in a dynamic environment.</p
><h3 id="who-makes-the-rundeck-software"
><a href="#TOC"
  ><span class="header-section-number"
    >1.1.1</span
    > Who makes the RunDeck software?</a
  ></h3
><p
>RunDeck is hosted at GitHub as a project called <a href="https://github.com/dtolabs/rundeck"
  >dtolabs/rundeck</a
  >. Dtolabs is a project where various open sources tools are being developed by <a href="http://www.dtosolutions.com"
  >DTO Solutions</a
  > engineers working in the field.</p
><p
>RunDeck is free software and is public under the Apache Software License.</p
><h3 id="why-is-rundeck-open-source"
><a href="#TOC"
  ><span class="header-section-number"
    >1.1.2</span
    > Why is RunDeck open source?</a
  ></h3
><p
>We believe this kind of software project must be open source because it is a new technology space and therefore ideas and code should be easily transferable.</p
><h3 id="why-is-it-called-rundeck"
><a href="#TOC"
  ><span class="header-section-number"
    >1.1.3</span
    > Why is it called RunDeck</a
  ></h3
><h2 id="rundeck-from-30000-feet"
><a href="#TOC"
  ><span class="header-section-number"
    >1.2</span
    > RunDeck from 30,000 feet</a
  ></h2
><h3 id="rundeck-in-the-tool-chain"
><a href="#TOC"
  ><span class="header-section-number"
    >1.2.1</span
    > RunDeck in the tool chain</a
  ></h3
><h3 id="rundeck-architecture"
><a href="#TOC"
  ><span class="header-section-number"
    >1.2.2</span
    > RunDeck architecture</a
  ></h3
><h2 id="getting-help"
><a href="#TOC"
  ><span class="header-section-number"
    >1.3</span
    > Getting help</a
  ></h2
><ul
><li
  >Mailing list: <a href="http://groups.google.com/group/rundeck-discuss"
    >http://groups.google.com/group/rundeck-discuss</a
    ><br
     /></li
  ><li
  >IRC: irc://irc.freenode.net/rundeck</li
  ><li
  >Unix manual pages: RunDeck installation includes a set of Unix manual pages describing the shell tools. <code>man -k rundeck</code></li
  ></ul
><h2 id="whats-next"
><a href="#TOC"
  ><span class="header-section-number"
    >1.4</span
    > What's next?</a
  ></h2
><p
>The remainder of the guide will give you a quick conceptual overview, and take you through installation and setup. After you are set up, you will learn about the distributed command dispatcher and how to use it to run ad-hoc commands. From there, you will learn about Jobs, defining multi-step procedures with Job workflows and how to parameterize them with options.</p
><p
>% RUNDECK(1) RunDeck User Manuals | Version 1.0 % Alex Honor % November 20, 2010</p
><h1 id="getting-started"
><a href="#TOC"
  ><span class="header-section-number"
    >2</span
    > Getting Started</a
  ></h1
><p
>This chapter will be about getting started with RunDeck. We will begin by explaining ... , then move on to ..., finally ... At the end of this chapter you should understand what RunDeck is, how you should use it and you should be all setup to do so.</p
><h2 id="rundeck-basics"
><a href="#TOC"
  ><span class="header-section-number"
    >2.1</span
    > RunDeck Basics</a
  ></h2
><p
>Several fundamental concepts underly and drive the development of the RunDeck system. If you are a new user, knowing about them will help you use and integrate RunDeck into your environment.</p
><h3 id="command-dispatching"
><a href="#TOC"
  ><span class="header-section-number"
    >2.1.1</span
    > Command dispatching</a
  ></h3
><p
>RunDeck supports a notion called Command dispatching wherein a user specifies dispatch critera along with an action (called a command) and this specification is used to perform a distributed execution.</p
><p
>Internally, a mechanism called the command dispatcher does a lookup to find node resources meeting specified filtering criteria and performs the distributed command execution. The command executes in a data context that contains information about the Node resource.</p
><p
>The command dispatcher supports two methods of command execution:</p
><ul
><li
  >Ad hoc commands: Execute any shell command or shell script across a set of hosts.<br
     /></li
  ><li
  >Jobs: Encapsulate commands as a named Job and tie them together into Job workflows.</li
  ></ul
><p
>RunDeck provides both graphical and command line interfaces to interact with the command dispatcher.</p
><h3 id="resource-model"
><a href="#TOC"
  ><span class="header-section-number"
    >2.1.2</span
    > Resource model</a
  ></h3
><p
>The command dispatcher works in conjunction with a resource model. A resource model is a representation of hosts deployed in your network. A <em
  >Node</em
  > resource is either a physical or virtual instance of an operating system that is network accessible.</p
><p
>Nodes have a number of basic properties but these properties can be extended to include arbitrary named key value pairs.</p
><p
>You can configure RunDeck to retrieve and store resource model data from any source, so long as it meets the RunDeck resource model document requirement.</p
><h3 id="authorization"
><a href="#TOC"
  ><span class="header-section-number"
    >2.1.3</span
    > Authorization</a
  ></h3
><p
>RunDeck uses an authorization model where users belong to groups and those groups are associated with abitrarily defined roles.</p
><p
>Every action executed through the RunDeck command dispatcher must meet the requirements of an access control policy definition.</p
><p
>Since RunDeck respects the ACLs definition, you can use role-based authorization to restrict some users to only a subset of actions. This provides a Self-Service type interface, where some users can have access to a limited set of actions to execute.</p
><h3 id="project"
><a href="#TOC"
  ><span class="header-section-number"
    >2.1.4</span
    > Project</a
  ></h3
><p
>All RunDeck activities occur within the context of a single project. Each project has its own resource model and Job store.</p
><p
>Multiple projects can be maintained on the same RunDeck server. Projects are independent of one another, so you can use them to organize unrelated systems within a single RunDeck installation. This can be useful for managing different infrastructures.</p
><h2 id="installing-rundeck"
><a href="#TOC"
  ><span class="header-section-number"
    >2.2</span
    > Installing RunDeck</a
  ></h2
><p
>Assuming the system requirements are met, RunDeck can be installed either from source, system package or via the launcher.</p
><h3 id="system-requirements"
><a href="#TOC"
  ><span class="header-section-number"
    >2.2.1</span
    > System Requirements</a
  ></h3
><p
>The following operating systems are known to support RunDeck:</p
><ul
><li
  >Linux: Most recent distributions are likely to work</li
  ><li
  >Windows: XP, Server and above</li
  ><li
  >Mac OS X 10.4 or later</li
  ><li
  >Solaris or OpenSolaris</li
  ></ul
><p
>Root (or Administrator on Windows) is not required or recommended. We recommend using a dedicated user account such as &quot;rundeck&quot;.</p
><p
>If there is need for root access, please set up the RunDeck user to have access via sudo.</p
><h4 id="java"
><a href="#TOC"
  ><span class="header-section-number"
    >2.2.1.1</span
    > Java</a
  ></h4
><p
>RunDeck is a Java-Servlet based server and therefore requires the Java runtime.</p
><p
>The install process requires that the latest version of Java 1.6 be installed. Both the <a href="http://openjdk.java.net/"
  >Open JDK</a
  > and <a href="http://java.com/"
  >Sun/Oracle</a
  > JVMs can be used. You must have the JAVA_HOME environment variable defined in your environment before running the install script.</p
><p
>Verify your Java version to check it meets the requirement:</p
><pre
><code
  >$ java -version
java version &quot;1.6.0_22&quot;
Java(TM) SE Runtime Environment (build 1.6.0_22-b04-307-10M3261)
Java HotSpot(TM) 64-Bit Server VM (build 17.1-b03-307, mixed mode)
</code
  ></pre
><h4 id="network-access"
><a href="#TOC"
  ><span class="header-section-number"
    >2.2.1.2</span
    > Network access</a
  ></h4
><p
>Cients should be set up to allow the RunDeck server user to connect to the clients using SSH via public-key authentication. It should not prompt for a password. There are various ways of installing SSH on Windows; we recommend <a href="http://www.cygwin.com/"
  >Cygwin</a
  >.</p
><p
>TCP ports 8080 and 1055 need to be open on the server. In addition, TCP port 22 needs to be open on the clients for SSH.</p
><p
>To check the ports are free on a Unix host run:</p
><pre
><code
  >netstat -an | egrep '8080|1055' 
</code
  ></pre
><p
>If the ports are in use on the server, you will see output similar to below:</p
><pre
><code
  >tcp46      0      0  *.8080                 *.*                    LISTEN
tcp46      0      0  *.1055                 *.*                    LISTEN
</code
  ></pre
><p
>The installation procedures describe how to choose different ports, if there is a conflict.</p
><h3 id="installing-from-source"
><a href="#TOC"
  ><span class="header-section-number"
    >2.2.2</span
    > Installing from Source</a
  ></h3
><p
>Checkout the sources from GitHub: https://github.com/dtolabs/rundeck</p
><p
>Run the build script:</p
><pre
><code
  >./build.sh
</code
  ></pre
><p
>Build clean</p
><pre
><code
  >./build.sh -clean
</code
  ></pre
><h3 id="installing-on-linux"
><a href="#TOC"
  ><span class="header-section-number"
    >2.2.3</span
    > Installing on Linux</a
  ></h3
><p
>If you want to install RunDeck on Linux via a binary installer, you can generally do so through the basic package-management tool that comes with your distribution. If you’re on Fedora, you can use yum:</p
><pre
><code
  >$ yum install rundeck
</code
  ></pre
><h3 id="installing-on-other-platforms"
><a href="#TOC"
  ><span class="header-section-number"
    >2.2.4</span
    > Installing on other platforms</a
  ></h3
><p
>Use the launcher as an alternative to a system package:</p
><ol style="list-style-type: decimal;"
><li
  >Download the launcher jar file.</li
  ><li
  ><p
    >Define RDECK_BASE environment variable to the location of the install</p
    ><pre
    ><code
      >export RDECK_BASE=$HOME/rundeck 
</code
      ></pre
    ></li
  ><li
  ><p
    >Create the directory for the installation.</p
    ><pre
    ><code
      >mkdir -p $RDECK_BASE 
</code
      ></pre
    ></li
  ><li
  ><p
    >Copy the launcher jar to the installation directory.</p
    ><pre
    ><code
      >cp rundeck-launcher-1.0.0.jar $RDECK_BASE
</code
      ></pre
    ></li
  ><li
  ><p
    >Change directory and start the jar.</p
    ><pre
    ><code
      >cd $RDECK_BASE    
java -jar rundeck-launcher-1.0.0.jar
</code
      ></pre
    ></li
  ><li
  ><p
    >Wait for the Started message.</p
    ><pre
    ><code
      >2010-11-19 13:35:51.127::INFO:  Started SocketConnector@0.0.0.0:8080
</code
      ></pre
    ></li
  ><li
  ><p
    >Update your shell environment</p
    ><pre
    ><code
      >PATH=$PATH:$RDECK_BASE/tools/bin
MANPATH=$MANPATH:$RDECK_BASE/man
</code
      ></pre
    ></li
  ></ol
><p
>If you get an error message that resembles the one below, you probably are using an unupported Java version.</p
><pre
><code
  >Exception in thread &quot;main&quot; java.lang.UnsupportedClassVersionError: Bad version number in .class file
</code
  ></pre
><h2 id="first-time-setup"
><a href="#TOC"
  ><span class="header-section-number"
    >2.3</span
    > First-Time Setup</a
  ></h2
><h3 id="logins"
><a href="#TOC"
  ><span class="header-section-number"
    >2.3.1</span
    > Logins</a
  ></h3
><p
>RunDeck supports a number of user directory configurations. By default, the installation uses a file based directory, but connectivity to LDAP is also available.</p
><p
>The RunDeck installation process will have defined a set of initial logins useful during the getting started phase.</p
><ul
><li
  >admin: Belongs to the &quot;admin&quot; group and is automatically granted the &quot;admin&quot; role privileges.</li
  ><li
  >deploy: Has access to run commands and jobs but unable to modify job definitions.</li
  ></ul
><h2 id="summary"
><a href="#TOC"
  ><span class="header-section-number"
    >2.4</span
    > Summary</a
  ></h2
><p
>You should have a basic understanding of what RunDeck. You should also now have a working version of RunDeck on your system that’s set up with your personal identity. It is now time to learn some RunDeck basics.</p
><p
>% RUNDECK(1) RunDeck User Manuals | Version 1.0 % Alex Honor % November 20, 2010</p
><h1 id="rundeck-basics-1"
><a href="#TOC"
  ><span class="header-section-number"
    >3</span
    > RunDeck Basics</a
  ></h1
><h2 id="rundeck-interfaces"
><a href="#TOC"
  ><span class="header-section-number"
    >3.1</span
    > RunDeck Interfaces</a
  ></h2
><p
>RunDeck provides two primary user interfaces:</p
><ul
><li
  >An HTML-based graphical console running as a webapp</li
  ><li
  >A suite of shell tools</li
  ></ul
><p
>Both interfaces allow you to view resources, dispatch commands, as well as, store and run jobs.</p
><h3 id="graphical-console"
><a href="#TOC"
  ><span class="header-section-number"
    >3.1.1</span
    > Graphical Console</a
  ></h3
><p
>To get started, go to the URL for your RunDeck server. Login to the web app with the credentials defined by the RunDeck user directory configuration. (The default installation username/password is: default/default)</p
><h4 id="navigation"
><a href="#TOC"
  ><span class="header-section-number"
    >3.1.1.1</span
    > Navigation</a
  ></h4
><p
>The RunDeck page header contains global navigation control to move between browsing Resources, History and Jobs. It also has links to logout and view the user's profile.</p
><dl
><dt
  >Resources</dt
  ><dd
  ><p
    >The Resources page displays the Node resources configured in your Project resource models. Like the Jobs and History pages a filter control can be used to limit the listing to just the Node resources matching the criteria.</p
    ></dd
  ><dt
  >History</dt
  ><dd
  ><p
    >From the History page, one can view currently executing commands in the &quot;Now Running&quot; area or browse execution history. The execution history can be filtered based on user selected parameters. Once the filter has been set, the matching history is displayed. The current filter settings also configure an RSS link, found in the top right of the page.</p
    ></dd
  ><dt
  >Jobs</dt
  ><dd
  ><p
    >From the Jobs page, one can list, create and run Jobs. A configurable filter allows a user to limit the Job listing to those Jobs matching the filtering criteria. These filter settings can be saved to a Users profile.</p
    ></dd
  ><dt
  >Admin</dt
  ><dd
  ><p
    >If your login belongs to the &quot;admin&quot; group and therefore granted &quot;admin&quot; privileges, a wrench icon will be displayed next to your login name. This page allows the admin to view group memberships for all users, as well as, edit their profile data.</p
    ></dd
  ><dt
  >Project menu</dt
  ><dd
  ><p
    >By default information about all projects is displayed. It is sometimes preferable to limit this information to just a particular project. The top navigation bar contains a menu to select the desired project.</p
    ></dd
  ></dl
><h3 id="shell-tools"
><a href="#TOC"
  ><span class="header-section-number"
    >3.1.2</span
    > Shell Tools</a
  ></h3
><p
>RunDeck includes a number of shell tools to dispatch commands, load and run Job definitions and interact with the execution queue. These are an alternative to those same functions accessible in the graphical console.</p
><dl
><dt
  >dispatch</dt
  ><dd
  >Execute ad hoc commands and scripts</dd
  ><dt
  >rd-queue</dt
  ><dd
  >Query the dispatcher for currently running Jobs and possibly kill them<br
     /></dd
  ><dt
  >rd-jobs</dt
  ><dd
  >List defined jobs as well as load them from text file definitions</dd
  ><dt
  >run</dt
  ><dd
  >Invoke the execution of a stored Job</dd
  ><dt
  >rd-project</dt
  ><dd
  >Setup a new RunDeck project</dd
  ><dt
  >rd-setup</dt
  ><dd
  >(Re-)configure an instance of RunDeck</dd
  ></dl
><p
>Consult the online manual pages for options and usage information.</p
><h2 id="project-setup"
><a href="#TOC"
  ><span class="header-section-number"
    >3.2</span
    > Project Setup</a
  ></h2
><p
>A RunDeck <em
  >Project</em
  > provides a space to manage related management activities.</p
><p
>A Project can be set up either inside the graphical console or via the command line.</p
><p
>After logging into the graphical console, you will notice a Project menu in the top navigation bar. If no projects exist, the menu will be replaced by a single button. Create a new project by pressing that button or choosing the &quot;Create a Project&quot; item from the menu. A dialog window will open prompting you for a project name.</p
><p
>After typing in your project name, RunDeck initializes it and returns you to the &quot;Resources&quot; view.</p
><p
>The <code>rd-project</code> shell tool can also be used to create a project.</p
><p
>On the RunDeck server, execute the <code>rd-project</code> command and specify a project name, here we use &quot;demo&quot;:</p
><pre
><code
  >rd-project -a create -p demo
</code
  ></pre
><p
>After running this command, you can login into the graphical console and see the new project in the project chooser menu.</p
><p
>The project setup process generates Project configuration in the server, and generate a bootstrap resource model containing information about the RunDeck server's host.</p
><h3 id="resource-model-1"
><a href="#TOC"
  ><span class="header-section-number"
    >3.2.1</span
    > Resource model</a
  ></h3
><p
>The initial resource model generated during project setup will contain information just about the RunDeck server host and is used just for bootstrapping the project. You can browse the resource model of a project by going to the &quot;Resources&quot; page.</p
><p
>In the shell, you can list the Node resources in a project resource model using the shell tool, <code>dispatch</code>. Specify project name using the <code>-p project</code> option.</p
><p
>Here the <code>dispatch</code> command lists the registered server for the &quot;demo&quot; project after the project setup. The <code>-v</code> gives a verbose listing that includes more detail:</p
><pre
><code
  >$ dispatch -p demo -v   
 strongbad:
    hostname: strongbad
    os-arch: x86_64
    os-family: unix
    os-name: Mac OS X
    os-version: 10.6.2
    tags: []
   ---- Attributes ----
</code
  ></pre
><p
>Node resources have standard properties, such as &quot;hostname&quot; but these can be extended via attributes. One of the more useful properties is the &quot;tags&quot; property. A tag is a text label that you give to the Node, perhaps denoting a classification, a role the node plays in the environment, or group membership.</p
><p
>The output above shows the &quot;strongbad&quot; node currently has an empty tags property: <code>tags: []</code>.</p
><p
>It is useful to start thinking about node tagging for the nodes you manage because you will use them later when specifying filtering options to drive distributed command dispatch.</p
><p
>Each Project has its configuration located in its own directory located in path like: <code>$RDECK_BASE/projects/<em
  >project</em
  >/etc/project.properties</code>.</p
><p
>This configuration contains two important properties for accessing and storing resource model data:</p
><ul
><li
  ><code>project.resources.file</code>: File path to store resource model data.</li
  ><li
  ><code>project.resources.url</code>: URL to the server providing the resource model data.</li
  ></ul
><p
>You can configure RunDeck to retrieve and store resource model data from any source, so long as it meets the RunDeck resource model document requirement.</p
><p
>RunDeck reads the XML document retrieved from the ${project.resources.url} site and stores it in the path defined by ${project.resources.file}.</p
><p
>Here's the XML document stored for the &quot;demo&quot; project that corresponds to the output printed by the <code>dispatch -v</code> shown earlier:</p
><pre
><code
  >&lt;project&gt;
    &lt;node name=&quot;strongbad&quot; type=&quot;Node&quot; 
      description=&quot;the RunDeck server host&quot; tags=&quot;&quot; 
      hostname=&quot;strongbad&quot; 
      osArch=&quot;x86_64&quot; osFamily=&quot;unix&quot; osName=&quot;Mac OS X&quot; osVersion=&quot;10.6.2&quot;
      username=&quot;alexh&quot; 
      editUrl=&quot;&quot; remoteUrl=&quot;&quot;/&gt;
&lt;/project&gt;
</code
  ></pre
><p
>Chances are you are maintaining information about your hosts within another tool, perhaps Chef, Puppet, Nagios, Amazon EC2, RightScale or even an in-house database. One of these other tools might be considered the authorative source of knowledge about the nodes deployed in your network, therefore it is best to create an interface to one of these tools and expose it as a web service to RunDeck. This could be done as a simple CGI script that does a transformation from the tool's format to the one RunDeck understands.</p
><p
>Of course, a rudimentary alternative is to maintain this information as an XML document, storing it in a source repository that is periodically exported to Rundeck. This method could be practical if your host infrastructure rarely changes.</p
><p
>The &quot;resource-v10&quot; manual contains reference information about the RunDeck resources document content and structure.</p
><p
>Check the RunDeck web site for providers to the RunDeck resource model.</p
><h2 id="command-execution"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3</span
    > Command Execution</a
  ></h2
><p
>RunDeck supports two modes of execution: <em
  >ad-hoc</em
  > commands and <em
  >Job</em
  >.</p
><p
>An <em
  >ad hoc</em
  > command is any system command or shell script executed via the command dispatcher. Ad hoc commands can be executed via a command line utility named <code>dispatch</code> or as a Job run from the graphical console.</p
><p
>A <em
  >Job</em
  > specifies a sequence of one or more command invocations that can be run once (i.e, is temporary) or named and stored for later use. Stored jobs can be started via the shell tool, <code>run</code>, and their progress checked with <code>rd-queue</code>.</p
><h3 id="dispatcher-options"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.1</span
    > Dispatcher options</a
  ></h3
><p
>Dispatcher execution can be controlled by various types of options.</p
><dl
><dt
  >Execution control</dt
  ><dd
  ><p
    >Command execution can be controlled in various ways. Concurrency is controlled through threadcount. Execution can continue if specified to keepgoing</p
    ></dd
  ><dt
  >Include and exclude patterns</dt
  ><dd
  ><p
    >Filtering options specify include and exclude patterns to determine which nodes from the project resource model to distribute commands.</p
    ></dd
  ><dt
  >Keywords</dt
  ><dd
  ><p
    >Keywords are used within they include and exclude patterns. The &quot;tags&quot; keywords additionally can use a boolean operator to combine logical ORs and ANDs.</p
    ></dd
  ><dt
  >Option combination</dt
  ><dd
  ><p
    >All keywords can be combined by specifying the include and exclude options multiple times on the command line.</p
    ></dd
  ></dl
><p
>One can experiment querying the resource model in the graphical console or with the <code>dispatch</code> tool.</p
><h4 id="filtering-nodes-graphically"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.1.1</span
    > Filtering nodes graphically</a
  ></h4
><p
>Node resources are displayed in the Resources page. Setting the project menu in the navigation bar will include Nodes to just those within that project's resource model.</p
><p
>Nodes can be filtered using include and exclude patterns by using the Filter form. The form can be opened by pressing the &quot;Filter&quot; link.</p
><p
>When the form opens, you will see it divided into an Include section where simple include expressions can be set, as well as, an &quot;Extended Filters...&quot; link where exclude expressions can be made.</p
><p
>After filling out the filter form, press &quot;Filter&quot; to generate a new listing. Pressing &quot;Clear&quot; resets the form.</p
><p
>The Include and Exclude filters allow for filtering nodes based on the following keywords: Name, Tags, Hostname, OS Name, OS Family, OS Architecture, OS Version and Type.</p
><h4 id="filtering-nodes-in-the-shell"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.1.2</span
    > Filtering nodes in the shell</a
  ></h4
><p
><code>dispatch</code> can use the commandline options -I (include) and -X (exclude) to specify which nodes to include and exclude from the base set of nodes. You can specify a single value, a list of values, or a regular expression as the argument to these options.</p
><p
><em
  >Examples</em
  ></p
><p
>List nodes with OS name, Linux:</p
><pre
><code
  >dispatch -p demo -I os-name=Linux
</code
  ></pre
><p
>List Linux nodes but exclude ones with names prefixed &quot;web.&quot;:</p
><pre
><code
  >dispatch -p demo -I os-name=Linux -X &quot;web.*&quot;
</code
  ></pre
><p
>List nodes that are tagged both &quot;web&quot; and &quot;prod&quot; :</p
><pre
><code
  >dispatch -p demo -I tags=web+prod
</code
  ></pre
><p
>Execute the <code>apachectl restart</code> command in 10 threads across all nodes tagged &quot;web&quot; and keepgoing in case an error occurs :</p
><pre
><code
  >dispatch -p demo -I tags=web -K -C 10 -- sudo apachectl restart 
</code
  ></pre
><p
>Consult the &quot;rd-options(1)&quot; manual page for the complete reference on available dispatcher options.</p
><h3 id="ad-hoc-commands"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.2</span
    > Ad-hoc commands</a
  ></h3
><p
>Typically, an &quot;ad hoc&quot; command is a shell script or system executable that you run at an interactive terminal. Ad hoc commands can be executed via the <code>dispatch</code> shell command or a graphical shell.</p
><h4 id="shell-tool-command-execution"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.2.1</span
    > Shell tool command execution</a
  ></h4
><p
>Use <code>dispatch</code> to execute individual commands or shell script files.</p
><p
>Here <code>dispatch</code> is used to run the Unix uptime command to print system status:</p
><pre
><code
  >$ dispatch -I os-family=unix -- uptime
[ctier@centos54 dispatch][INFO]  10:34:54 up 46 min,  2 users,  load average: 0.00, 0.00, 0.00
[alexh@strongbad dispatch][INFO] 10:34  up 2 days, 18:51, 2 users, load averages: 0.55 0.80 0.75
[demo@ubuntu dispatch][INFO]  10:35:01 up 2 days, 18:40,  2 users,  load average: 0.00, 0.01, 0.00
</code
  ></pre
><p
>Notice, the <code>dispatch</code> command prepends the message output with a header that helps understand from where the output originates. The header format includes the login and node where the <code>dispatch</code> execution occurred.</p
><p
>Execute the Unix <code>whomi</code> command to see what user ID is used by that Node to run dispatched commands:</p
><pre
><code
  >$ dispatch -I os-family=unix -- whoami
[ctier@centos54 dispatch][INFO] ctier
[alexh@strongbad dispatch][INFO] alexh
[demo@ubuntu dispatch][INFO] demo
</code
  ></pre
><p
>You can see that the resource model defines each Node to use a different login to execute <code>dispatch</code> commands. That feature can be handy when Nodes serve different roles and therefore, use different logins to manage processes. See the <code>username</code> attribute in &quot;resource-v10(1)&quot; manual page.</p
><p
>The <code>dispatch</code> command can also execute shell scripts. Here's a trivial script that generates a bit of system info:</p
><pre
><code
  >#!/bin/sh
echo &quot;info script&quot;
echo uptime=`uptime`
echo whoami=`whoami`
echo uname=`uname -a`
</code
  ></pre
><p
>Use the -s option to specify the &quot;info.sh&quot; script file:</p
><pre
><code
  >$ dispatch -I os-family=unix -s info.sh
</code
  ></pre
><p
>The <code>dispatch</code> command copies the &quot;info.sh&quot; script located on the server to each &quot;unix&quot; Node and then executes it.</p
><h4 id="graphical-command-shell-execution"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.2.2</span
    > Graphical command shell execution</a
  ></h4
><p
>The RunDeck graphical console also provides the ability to execute ad-hoc commands to a set of filtered Node resources. The command prompt can accept any ad-hoc command string you might run via an SSH command or via the <code>dispatch</code> shell tool.</p
><p
>But before running any commands, you need to select the project containing the Nodes you wish to dispatch. Use the project menu to select the desired project name. After the project has been selected you will see a long horizontal textfield labeled &quot;Command&quot;. This is the RunDeck command prompt tool bar.</p
><p
>To use the command prompt, type the desired ad-hoc command string into the textfield and press the &quot;Run&quot; button. The command will be dispatched to all the Node resources currently listed below the command prompt tool bar.</p
><p
>If the project selection menu was just chosen, then all Node resources in that project resource model will be listed. You will most likely want to limit the execution of your ad-hoc command to a subset of these.</p
><p
>Use the filter control to refine the list of Nodes to target for your ad-hoc command. Press the &quot;Filter&quot; link to open the filter control form. Inside the filter form you will see an area to define an include filter expression and a link to &quot;Extended Filters...&quot; where an exclusion expression can also be defined. Many simple cases can use either a regex pattern on Node name or a tag expression. Type in the desired filter expression and press the &quot;Filter&quot; button to refine the Node listing and redisplay the command prompt tool bar.</p
><p
>Once you are satisifed with the Node listing, input the ad-hoc command string, then press the &quot;Run&quot; button to begin execution. The browser will be directed to a page where execution output can be followed.</p
><h5 id="following-execution-output"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.2.2.1</span
    > Following execution output</a
  ></h5
><p
>Command execution is displayed on a spearate page. This page provides several views to read the output using different formats.</p
><dl
><dt
  >Tail Output</dt
  ><dd
  ><p
    >Displays output messages from the command execution as if you were running the Unix <code>tail -f</code> command on the output log file. By default, only the last 20 lines of output is displayed but this can be expanded or reduced by pressing the &quot;-&quot; or &quot;+&quot; buttons. You can also type in an exact number into the textfield.</p
    ></dd
  ><dt
  >Annotated</dt
  ><dd
  ><p
    >The annotated mode displays the output messages in the order they are received but labels the each line with the Node from which the message originated. Through its additional controls each Node context can be expanded to show the output it produced, or completely collapsed to hide the textual detail.</p
    ></dd
  ><dt
  >Node Output</dt
  ><dd
  ><p
    >Output messages are sorted into Node specific sections and are not interlaced. By default, the messages are collapsed but can be revealed by pressing the disclosure icon to the right.</p
    ></dd
  ></dl
><p
>Also, notice the URL in the location bar of your browser. This URL can be shared to others interested in the progress of execution. The URL contains the execution ID (EID) and has a form like:</p
><pre
><code
  > http://rundeckserver/execution/follow/{EID}
</code
  ></pre
><p
>After execution completes, the command will have a status:</p
><ul
><li
  >Successful: No errors occurred during execution of the command across the filtered Node set</li
  ><li
  >Failed: One or more errors occurred. A list of Nodes that incurred an error is displayed. The page will also contain a link &quot;Retry Failed Nodes...&quot; in case you would like to retry the command.</li
  ></ul
><p
>A URL also exists for this page which can be used later to refer to this execution:</p
><pre
><code
  > http://rundeckserver/execution/show/{EID}
</code
  ></pre
><p
>You can download the entire output as a text file from this page. Press the &quot;Download&quot; link to retrieve the file to your desk top.</p
><h3 id="controlling-ad-hoc-command-execution"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.3</span
    > Controlling ad-hoc command execution</a
  ></h3
><p
>Parallel execution is managed using thread count via &quot;-C&quot; option. The &quot;-C&quot; option specifies to the number of execution threads. Here's an example that runs the uptime command across the Linux hosts with two threads:</p
><pre
><code
  >dispatch -I os-name=Linux -C 2 -- uptime
</code
  ></pre
><p
>The keepgoing and retry flags control when to exit incase an error occurs. Use &quot;-K/-R&quot; flags. Here's an example script that checks if the host has port 8080 in the listening state. If it does not, it will exit with code 1.</p
><pre
><code
  >#!/bin/sh
netstat -an | grep 8080 | grep -q LISTEN
if [ &quot;$?&quot; != 0 ]; then
echo &quot;not listening on 8080&quot;
exit 1;
fi
echo  listening port=8080, host=`hostname`;
</code
  ></pre
><p
>Commands or scripts that exit with a non-zero exit code will cause the dispatch to fail unless the keepgoing flag is set.</p
><pre
><code
  >$ dispatch -I os-family=unix -s /tmp/listening.sh
[alexh@strongbad dispatch][INFO] Connecting to centos54:22
[alexh@strongbad dispatch][INFO] done.
[ctier@centos54 dispatch][INFO] not listening on 8080
error: Remote command failed with exit status 1
The script failed on centos54 and caused dispatch to error out immediately.
</code
  ></pre
><p
>Running the command again, but this time with the &quot;-K&quot; keepgoing flag will cause dispatch to continue and print on which nodes the script failed:</p
><pre
><code
  >$ dispatch -K -I tags=web -s /tmp/listening.sh
[alexh@strongbad dispatch][INFO] Connecting to centos54:22
[alexh@strongbad dispatch][INFO] done.
[ctier@centos54 dispatch][INFO] not listening on 8080
[ctier@centos54 dispatch][ERROR] Failed execution for node: centos54: Remote command failed with exit status 1
[alexh@strongbad dispatch][INFO] listening port=8080, host=strongbad
[alexh@strongbad dispatch][INFO] Connecting to 172.16.167.211:22
[alexh@strongbad dispatch][INFO] done.
[demo@ubuntu dispatch][INFO] not listening on 8080
[demo@ubuntu dispatch][ERROR] Failed execution for node: ubuntu: Remote command failed with exit status 1
error: Execution failed on the following 2 nodes: [centos54, ubuntu]
error: Execute this command to retry on the failed nodes:
    dispatch -K -s /tmp/listening.sh -p demo -I
    name=centos54,ubuntu
</code
  ></pre
><h3 id="queuing-commands-to-rundeck"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.4</span
    > Queuing commands to RunDeck</a
  ></h3
><p
>Commands or scripts executed on the command line by dispatch can also be queued as temporary jobs in RunDeck by using the &quot;-Q&quot; option. The dispatch -Q usage is equivalent to a &quot;Run and Forget&quot; action in the graphical console.</p
><p
>The script below is a long running check that will conduct a check periodically waiting a set time between each pass. The script can be run with or without arguments as the parameters are defaulted inside the script:</p
><pre
><code
  >$ cat ~/bin/checkagain.sh 
#!/bin/bash
iterations=$1 secs=$2 port=$3
echo &quot;port ${port:=8080} will be checked ${iterations:=30} times waiting ${secs:=5}s between each iteration&quot; 
i=0
while [ $i -lt ${iterations} ]; do
  echo &quot;iteration: #${i}&quot;
  netstat -an | grep $port | grep LISTEN &amp;&amp; exit 0
  echo ----
  sleep ${secs}
  i=$(($i+1))
done
echo &quot;Not listening on $port after $i checks&quot; ; exit 1
</code
  ></pre
><p
>Running dispatch with the -Q option causes the execution to queue in RunDeck and controlled as temporary Job. The -I centos54 limits execution to just the &quot;centos54&quot; node:</p
><pre
><code
  >$ dispatch -Q -I centos54 -s ~/bin/checkagain.sh 
Succeeded queueing workflow: Workflow:(threadcount:1){ [command( scriptfile: /Users/alexh/bin/checkagain.sh)] }
Queued job ID: 5 &lt;http://strongbad:8080/execution/follow/4&gt;
</code
  ></pre
><p
>To pass arguments to the script pass them after the &quot;--&quot; (double dash):</p
><pre
><code
  >$ iters=5 secs=60 port=8080
$ dispatch -Q -I centos54 -s ~/bin/checkagain.sh -- $iters $secs $ports
</code
  ></pre
><h3 id="tracking-execution"
><a href="#TOC"
  ><span class="header-section-number"
    >3.3.5</span
    > Tracking execution</a
  ></h3
><p
>Queued ad-hoc command and temporary or saved Job executions can be tracked from the &quot;History&quot; page in the &quot;Now Running&quot; area at the top of the page.</p
><p
>This page provides a listing of all running executions, when they started, who started them and an approximation of their completion progress.</p
><p
>Users with &quot;workflow_kill&quot; privilege, will also see a link to kill the Job in case they want to stop it immediatly.</p
><p
>Execution can also be tracked using the <code>rd-queue</code> shell tool.</p
><pre
><code
  >$ rd-queue
Queue: 1 items
[5] workflow:
Workflow:(threadcount:1){[command( scriptfile: /Users/alexh/bin/checkagain.sh)]
} &lt;http://strongbad:8080/execution/follow/5&gt;
</code
  ></pre
><p
>Running jobs can also be killed via the rd-queue &quot;kill&quot; command. The rd-queue command includes the execution ID for each running job. Specify execution ID using the &quot;-e&quot; option:</p
><pre
><code
  >$ ctl-queue kill -e 5
ctl-queue kill: success. [5] Job status: killed
</code
  ></pre
><p
>Show now running page...</p
><h2 id="history"
><a href="#TOC"
  ><span class="header-section-number"
    >3.4</span
    > History</a
  ></h2
><p
>History for queued ad-hoc commands, as well as, temporary and saved Job executions is stored in by the RunDeck server. History data can be filtered and viewed inside the &quot;History&quot; page of the graphical console.</p
><h3 id="filtering-event-history"
><a href="#TOC"
  ><span class="header-section-number"
    >3.4.1</span
    > Filtering event history</a
  ></h3
><p
>By default, the History page will list history for the last day's executions. The page contains a filter control that can be used to expand or limit the executions.</p
><p
>The filter form contains a number of fields to limit search:</p
><ul
><li
  >Within: Time range. Choices include 1 day, 1 week, 1 month or other (given a start after/before to ended after/before).</li
  ><li
  >Job Name: Job title name.</li
  ><li
  >Project: Project name. This may be set if the project menu was used.</li
  ><li
  >Resource: Name of project resource.</li
  ><li
  >User: User initiating action.</li
  ><li
  >Node: Node name.</li
  ><li
  >Tags: Event tag name.</li
  ><li
  >Report ID: Report identifier.</li
  ><li
  >Message: Message text.</li
  ><li
  >Result: Success or failure status.</li
  ></ul
><p
>After filling the form pressing the &quot;Filter&quot; button, the page will display events matching the search.</p
><p
>Filters can be saved to a menu that makes repeating searches more convenient. Click the &quot;save this filter...&quot; link to save the filter configuration.</p
><h3 id="event-view"
><a href="#TOC"
  ><span class="header-section-number"
    >3.4.2</span
    > Event view</a
  ></h3
><p
>History for each execution contains the command(s) executed, dispatcher options, success status and a link to a file containing all the output messages.</p
><h3 id="rss-link"
><a href="#TOC"
  ><span class="header-section-number"
    >3.4.3</span
    > RSS Link</a
  ></h3
><p
>An RSS icon provides a link to an RSS view of the events that match the current filtering critera.</p
><h2 id="tips-and-tricks"
><a href="#TOC"
  ><span class="header-section-number"
    >3.5</span
    > Tips and Tricks</a
  ></h2
><h3 id="saving-filters"
><a href="#TOC"
  ><span class="header-section-number"
    >3.5.1</span
    > Saving filters</a
  ></h3
><p
>Each of the filter controls provides the means to save the current filter configuration. Press the &quot;save this filter...&quot; link to give it a name. Each saved filter is added to a menu you can access the next time you want that filter configuration.</p
><h3 id="auto-completion"
><a href="#TOC"
  ><span class="header-section-number"
    >3.5.2</span
    > Auto-Completion</a
  ></h3
><p
>If you use the Bash shell, RunDeck comes with a nice auto-completion script you can enable. Add this to your <code
  >.bashrc</code
  > file:</p
><pre
><code
  >source $RDECK_BASE/etc/bash_completion.bash
</code
  ></pre
><p
>Press the Tab key when you're writing a Git command, and it should return a set of suggestions for you to pick from:</p
><pre
><code
  >$ dispatch &lt;tab&gt;&lt;tab&gt;
</code
  ></pre
><h2 id="summary-1"
><a href="#TOC"
  ><span class="header-section-number"
    >3.6</span
    > Summary</a
  ></h2
><p
>At this point, you can do basic RunDeck operations - setup a project, define and query the project resource model, execute ad-hoc commands, run and save Jobs and view history.</p
><p
>Next, we'll cover one of RunDeck's core features: Jobs.</p
><p
>% RUNDECK(1) RunDeck User Manuals | Version 1.0 % Alex Honor % November 20, 2010</p
><h1 id="jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4</span
    > Jobs</a
  ></h1
><p
>In previous sections of this manual, you learned how to execute ad-hoc commands across a filtered set of Node resources. This chapter introduces a fundamental RunDeck feature, <em
  >Jobs</em
  >. But first, one might ask why introduce another layer over ad-hoc command execution.</p
><p
>Here are some issues that might arise over time:</p
><ul
><li
  >One might find certain ad-hoc command executions are repeated, and perhaps, represent what has become a routine procedure.</li
  ><li
  >Another user in your group needs a simple self-service interface to run a procedure across a set of nodes.</li
  ><li
  >Routine procedures need to be encapsulated and be the basis for other routine procedures.</li
  ></ul
><p
>Jobs provide a means to encapsulate a procedure in a logically named Job. A <em
  >Job</em
  > is a configuration representing the steps in a procedure, a Node filter specification, and dispatcher execution control parameters. Jobs access is governed by an access control policy that describes how users are granted authorization to use Jobs.</p
><p
>RunDeck lets you organize and execute Jobs, and observe the output as the Job is running. You can view a list of the currently running Jobs that is dynamically updated as the Jobs progress. Jobs can also be killed if they need to be stopped.</p
><p
>Each Job has a record of every time it has been executed, and the output from those executions can be viewed.</p
><p
>The next sections describes how to navigate and run existing Jobs. In later sections, the topic of Job creation will be covered.</p
><p
>If you want to skip ahead, you can go straight to <a href="#creating-jobs"
  >Creating Jobs</a
  >.</p
><h2 id="job-groups"
><a href="#TOC"
  ><span class="header-section-number"
    >4.1</span
    > Job groups</a
  ></h2
><p
>As many jobs will accumulate over time, it is useful to organize Jobs into groups. A group is a logical set of jobs, and one job group can exist inside another. RunDeck displays job lists as a set of folders corresponding to the group structure your jobs define.</p
><p
>Beyond organizing jobs, groups assist in defining access control policy, as we'll cover later in the Authorization chapter.</p
><h2 id="listing-and-filtering-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.2</span
    > Listing and filtering Jobs</a
  ></h2
><p
>All Job activity begins on the main &quot;Jobs&quot; page inside RunDeck. After logging in, press the &quot;Jobs&quot; button in the top navigation bar and any Jobs you are authorized to see will be displayed.</p
><p
>If the Jobs were defined inside groups, you will see the listing grouped into a folder like structure. These folders represent the Job groups described earlier. You can navigate these folders by pressing the folder icon to reveal its contents.</p
><p
>Once you have navigated to a Job, you will see its name, possibly its description and a summary total of how many times it has been executed.</p
><p
>Clicking on the job name will will expand the window to show the Job detail. You will see a button bar containing icons representing the actions you are able to perform. Other Job detail will include what command(s) it will run, filter expressions and other dispatcher options.</p
><h3 id="filtering-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.2.1</span
    > Filtering Jobs</a
  ></h3
><p
>The Job page lets you search for Jobs using the Filter option.</p
><p
>Click the &quot;Filter&quot; link to show the filter options:</p
><p
>This will show the Filter fields:</p
><p
>Enter a value in any of the filter fields:</p
><ul
><li
  >Job Name: the name of the job</li
  ><li
  >Group: the name of the job group</li
  ><li
  >Description: Job description text</li
  ></ul
><p
>You can type a substring or a regular expression in any of these fields.</p
><p
>After pressing the &quot;Filter&quot; button, the Job list will be filtered to include only the matching jobs.</p
><p
>To refine the filter, click on the blue-outlined Filter description, and change the filter fields.</p
><p
>To reset the filter and go back to the full job page, click the &quot;Clear&quot; button in the Filter fields.</p
><h2 id="running-a-job"
><a href="#TOC"
  ><span class="header-section-number"
    >4.3</span
    > Running a Job</a
  ></h2
><p
>Any stored job can be started from the Job page by pressing the green &quot;Run&quot; icon in the Job control bar. If you do not see the Run icon, it means your login does not have &quot;run&quot; privileges.</p
><p
>Jobs can also be started from the command line using the <code>run</code> shell tool.</p
><p
>Here's an example that starts a hypothetical job named &quot;restart&quot; belonging in the &quot;apps/web&quot; Job group:</p
><pre
><code
  >$ run -j apps/web/restart
Job execution started:
[51] restart &lt;http://strongbad:8080/execution/follow/51&gt;
</code
  ></pre
><p
>After the Run button has been pressed the page will be directed to choose execution options.</p
><h3 id="choose-execution-options"
><a href="#TOC"
  ><span class="header-section-number"
    >4.3.1</span
    > Choose execution options</a
  ></h3
><p
>Jobs can be defined to prompt the user for options. This page contains a form presenting any of these Job options.</p
><p
>Some options will have default values while others may present you with a menu of choices. Some options are optional while others are required. Lastly, their might be a pattern govering what values are acceptable.</p
><p
>If there are any such Job options, you can change them here before proceeding with the execution.</p
><p
>When you are ready press &quot;Run Job Now&quot; page and you will be directed to page where you can follow the progress of the Job. You can press the &quot;Cancel&quot; button</p
><h3 id="following-running-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.3.2</span
    > Following Running Jobs</a
  ></h3
><p
>Once you have started running a Job, you can follow the output of the job in the Execution Follow page.</p
><p
>Depending where you are in the RunDeck console, you can track a running Job starting from several locations:</p
><ul
><li
  ><p
    >If you have just pressed the Run button for a Job and chose its execution options and pressed &quot;Run Job Now&quot; you will automatically be directed to this page.</p
    ></li
  ><li
  ><p
    >From the Jobs page, you can click to the Job you are interested in tracking and click the spinning cursor icon labeled &quot;now&quot;.</p
    ></li
  ><li
  ><p
    >From the History page, open the &quot;Now Running&quot; area adn then click on the &quot;output »&quot; link for the running execution.</p
    ></li
  ></ul
><h2 id="creating-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.4</span
    > Creating Jobs</a
  ></h2
><p
>With RunDeck you can define two kinds of Jobs.</p
><ul
><li
  >Temporary: A temporary Job defines a set of commands to execute and a node filter configuration.</li
  ><li
  >Saved: Saved jobs also define a set of commands to execute and dispatcher options but can be given a name and stored in a group. Additionally, saved Jobs can be given an execution schedule.</li
  ></ul
><h3 id="temporary-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.4.1</span
    > Temporary Jobs</a
  ></h3
><p
>A temporary job is a bit like an ad-hoc command except you get more controls about how the commands will execute plus the execution can be tracked tracked within the RunDeck webapp.</p
><p
>To create a temporary job, begin by logging in to the RunDeck webapp, and press the &quot;Jobs&quot; tab.</p
><ol style="list-style-type: decimal;"
><li
  >Locate the &quot;New Job&quot; button in the right hand corner and press it to display the &quot;Create New Job&quot; form.</li
  ><li
  >A job is defined in terms of one or more workflow steps. In the Workflows area, click the &quot;Add a step&quot; link.</li
  ><li
  >Workflow steps can be one of several types. Click the &quot;Script&quot; workflow step type.</li
  ><li
  >A script type can be any script that can be executed on the target hosts. Type in the &quot;info&quot; shell script we executed earlier using dispatch.</li
  ><li
  >At the bottom of the form, push the &quot;Run and Forget&quot; button to begin execution.</li
  ><li
  >Execution output can be followed on the subsequent page.</li
  ></ol
><h3 id="saved-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.4.2</span
    > Saved Jobs</a
  ></h3
><p
>Running ad hoc commands and temporary jobs are a typical part of day to day administrative tasks. Occasionally, ad-hoc commands become routine procedures and if were reusable, would become valuable as they could be handed off to others in the team or invoked from within other Jobs. RunDeck provides an interface to declare and save jobs, both graphically or declared with an XML file.</p
><h3 id="simple-saved-job"
><a href="#TOC"
  ><span class="header-section-number"
    >4.4.3</span
    > Simple saved job</a
  ></h3
><p
>For the first saved Job example, create a Job that calls the info script.</p
><ol style="list-style-type: decimal;"
><li
  >Like in the earlier example, begin by pressing the &quot;New Job&quot; button.</li
  ><li
  >Within the new job form:<ul
    ><li
      >Select &quot;Yes&quot; for the &quot;Save this job?&quot; prompt. Pressing Yes reveals a form to define a name, group and description for the job.</li
      ><li
      >For &quot;Job Name&quot;, enter &quot;info&quot; and for the &quot;Group&quot;, enter &quot;adm/resources&quot;.</li
      ><li
      >Providing a description will be come helpful to other users to understand the intent and purpose for the Job.</li
      ><li
      >Check the box for &quot;Dispatch to Nodes&quot;</li
      ><li
      >Choose the &quot;Node Exclude Filters&quot; and enter the name of your RunDeck server. This will cause the job to run on just the remote Nodes (eg., centos54 and ubuntu).</li
      ><li
      >Type in the info script that we used earlier.</li
      ><li
      >Save the script changes in the Workflow editor.</li
      ><li
      >Press the &quot;Create&quot; button at the bottom of the page.</li
      ></ul
    ></li
  ><li
  >After the the job is created, the browser is directed to the Jobs page. The folder structure reflecting the group naming will show one Job.<ul
    ><li
      >Press through the folders and then to the job itself</li
      ></ul
    ></li
  ><li
  >Notice the button bar with controls for editing and running the job.<ul
    ><li
      >Press the green arrow icon to run the Job.</li
      ></ul
    ></li
  ><li
  >Press the &quot;Run Job Now&quot; button to begin execution.<ul
    ><li
      >Output from the script execution from the target Nodes will be displayed on the subsequent page.</li
      ></ul
    ></li
  ></ol
><h2 id="scheduled-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.5</span
    > Scheduled Jobs</a
  ></h2
><p
>Saved jobs can be configured to run on a periodic basis. If you want to create a Scheduled Job, select Yes under &quot;Schedule to run repeatedly?&quot;</p
><p
>The schedule can be defined in a simple graphical chooser or Unix crontab format.</p
><p
>To use the simple chooser, choose an hour and minute. You can then choose &quot;Every Day&quot; (default), or uncheck that option and select individual days of the week. You can select &quot;Every Month&quot; (default) or unselect that option and choose specific months of the year:</p
><p
>If the crontab time and date format is preferred, enter a cron expression.</p
><p
>The exact crontab syntax used is referenced here: <a href="http://www.quartz-scheduler.org/docs/api/1.8.1/org/quartz/CronExpression.html"
  >CronExpression</a
  ></p
><h2 id="job-history"
><a href="#TOC"
  ><span class="header-section-number"
    >4.6</span
    > Job history</a
  ></h2
><p
>In the Jobs page, you can see the outcome of previous executions of Jobs by clicking the &quot;Executions&quot; link for the Job. This returns a filtered history peraining to that Job. You can click on any past execution in the list to see the full execution state.</p
><h2 id="killing-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.7</span
    > Killing Jobs</a
  ></h2
><p
>Jobs that are currently running can be Killed immediately.</p
><p
>WARNING: This feature should be used with caution, as it forcibly kills the Java Thread that the Job is running on. It may result in the RunDeck server becoming flaky. It is a deprecated feature of Java that is not recommended to be used, so do so only when extremely necessary.</p
><p
>From the History view Now Running section, or in the Job execution follow page, click on the &quot;Kill Job Now&quot; button for the running Job.</p
><p
>When prompted &quot;Really kill this job?&quot; Click the &quot;Yes&quot; button.</p
><p
>The Job will terminate with a &quot;Killed&quot; completion status.</p
><h2 id="deleting-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.8</span
    > Deleting Jobs</a
  ></h2
><p
>In the Jobs, click the red &quot;X&quot; icon for the Job you want to delete.</p
><p
>Click &quot;Yes&quot; when it says &quot;Really delete this Job?&quot;</p
><h2 id="updating-and-copying-jobs"
><a href="#TOC"
  ><span class="header-section-number"
    >4.9</span
    > Updating and copying Jobs</a
  ></h2
><p
>All of the data you set when creating a job can be modified. To edit a Job, you can either click the Pencil icon in the Job list:</p
><p
>Similarly, to Copy a Job definition to a new Job, choose the Copy icon or the Copy button.</p
><h2 id="exporting-jobs-as-xml"
><a href="#TOC"
  ><span class="header-section-number"
    >4.10</span
    > Exporting Jobs as XML</a
  ></h2
><p
>Job definitions created inside the RunDeck graphical console can be exported to an XML file format and be used for later import.</p
><p
>Two methods exist to retrieve the XML definition one inside RunDeck's graphical interface and the other using the <code>rd-jobs</code> shell tool.</p
><p
>From RunDeck's Job page navigate to the Job you wish to export. Locate the icon with an XML symbol in the toolbar. It is labeled &quot;Download XML&quot; in the mouse tool tip.</p
><p
>Press this button to initiate the file download to your browser. Depending on your browser, it will be stored to your downloads directory.</p
><p
>If you prefer the command line open a shell on the RunDeck server. Run the <code>rd-jobs</code> command to write it to disk. By default, rd-jobs will dump all Job definitions to one file. To limit it to just a single Job specify its name:</p
><pre
><code
  >rd-jobs -n &quot;job-name&quot; -f jobs.xml
</code
  ></pre
><p
>This will store the results in the &quot;jobs.xml&quot; file.</p
><p
>Consult the &quot;rd-jobs(1)&quot; manual page for additional command usage.</p
><h2 id="importing-jobs-as-xml"
><a href="#TOC"
  ><span class="header-section-number"
    >4.11</span
    > Importing Jobs as XML</a
  ></h2
><p
>If you have a &quot;jobs.xml&quot; file (See above) and want to upload it via the GUI web interface, you can do so.</p
><p
>Click on the New Job&quot; button in the Job list.</p
><p
>In the &quot;Create New Job&quot; form, click on the button that says &quot;Uplaod Definition...&quot; on the right side:</p
><p
>Click the Choose File button and choose your jobs.xml file to upload.</p
><p
>Choose an option where it says &quot;When a job with the same name already exists:&quot;:</p
><ul
><li
  >Update - this means that a job defined in the xml will overwrite any existing job with the same name<br
     /></li
  ><li
  >Skip - this means that a job defined in the xml will be skipped over if there is an existing job with the same name<br
     /></li
  ><li
  >Create - this means that the job defined in the xml will be used to create a new job if there is an existing job with the same name.</li
  ></ul
><p
>Click the Upload button. If there are any errors with the Job definitions in the XML file, they will show up on the page.</p
><h2 id="summary-2"
><a href="#TOC"
  ><span class="header-section-number"
    >4.12</span
    > Summary</a
  ></h2
><p
>Next, we'll cover how to create multi-step procedures using Job Workflows.</p
><p
>% RUNDECK(1) RunDeck User Manuals | Version 1.0 % Alex Honor % November 20, 2010</p
><h1 id="job-workflows"
><a href="#TOC"
  ><span class="header-section-number"
    >5</span
    > Job Workflows</a
  ></h1
><p
>The Job's most basic feature is its ability to execute one or more commands across a set of nodes. This sequence of commands is called a <em
  >workflow</em
  >, and each step in the workflow is defined as an invocation to a command.</p
><p
>The steps of the Job workflow are displayed when viewing a Job's detail from a Job listing or within the Job editor form.</p
><h2 id="authoring-tools"
><a href="#TOC"
  ><span class="header-section-number"
    >5.1</span
    > Authoring tools</a
  ></h2
><p
>Workflows can be defined within the RunDeck graphical console or as an XML document that is loaded to the server.</p
><p
>The graphical console provides an authoring environment where steps can be added, edited, removed or reordered.</p
><p
>Users prefering to define Jobs in XML should read the &quot;job-v10(1)&quot; manual page.</p
><p
>It is also possible to author Jobs inside the graphical console and then export the definiton as an XML file using the <code>rd-jobs</code> shell tool (man &quot;rd-jobs(1)&quot;).</p
><h2 id="workflow-control-settings"
><a href="#TOC"
  ><span class="header-section-number"
    >5.2</span
    > Workflow control settings</a
  ></h2
><p
>Workflow execution is controlled by two important settings: <em
  >Keepgoing</em
  > and <em
  >Strategy</em
  >.</p
><p
><em
  >Keepgoing</em
  >: This manages what to do if a step incurs and error:</p
><ul
><li
  >No: Fail immediately (default)</li
  ><li
  >Yes: Continue to next step</li
  ></ul
><p
>The default is to fail immediately but depending on the procedure at hand you can choose to have the execution continue.</p
><p
><em
  >Strategy</em
  >: Controls the order of execution of steps and command dispatch to nodes: <em
  >Node-oriented</em
  > and <em
  >Step-oriented</em
  >.</p
><ul
><li
  ><em
    >Node-oriented</em
    >: Executes the full workflow on each node before the next node. (default)</li
  ><li
  ><em
    >Step-oriented</em
    >: Executes each step on all nodes before the next node.</li
  ></ul
><p
>The following illustrations contrast the strategies showing how three steps proceed across two nodes.</p
><p
>Node-oriented flow illustrated:</p
><pre
><code
  >1.   NodeA    step#1
2.     &quot;      step#2
3.     &quot;      step#3
4.   NodeB    step#1
5.     &quot;      step#2
6.     &quot;      step#3
</code
  ></pre
><p
>Step-oriented flow illustrated:</p
><pre
><code
  >1.   NodeA    step#1
2.   NodeB      &quot;
3.   NodeA    step#2
4.   NodeB      &quot;
5.   NodeA    step#1
6.   NodeB      &quot;
</code
  ></pre
><p
>The process you are automating will determine which strategy is correct, though the node-oriented flow is more commonplace.</p
><h2 id="workflow-steps"
><a href="#TOC"
  ><span class="header-section-number"
    >5.3</span
    > Workflow steps</a
  ></h2
><p
>The following sections describe how to construct a workflow as a set of steps that call commands of different types.</p
><p
>When creating a new Job definition, the Workflow form will be set with defaults and have no workflow steps defined. The workflow editor will have a form open asking to enter a shell command as the first step.</p
><p
>To add new steps simply press the &quot;Add a step&quot; link inside the workflow editor form. This will prompt you with a dialog asking which kind of workflow step you would like to add. Each kind of step has its own form. When you are done filling out the form, press &quot;Save&quot; to add it to the sequence. Pressing &quot;Cancel&quot; will close the form and leave the sequence unchanged.</p
><p
>New steps are always added to the end of the sequence. See <a href="#reordering-steps"
  >Reordering steps</a
  > for directions on modifying the step order.</p
><p
>The next several sections describe the specification of each kind of command step.</p
><h3 id="command-step"
><a href="#TOC"
  ><span class="header-section-number"
    >5.3.1</span
    > Command step</a
  ></h3
><p
>Use the command step to call system commands. This is the default type of workflow step when creating a Job. Enter any command string you would type at the terminal on the remote hosts.</p
><p
>This is similar to calling the command with <code>dispatch</code>:</p
><pre
><code
  >dispatch [filter-options] -- command
</code
  ></pre
><h3 id="script-step"
><a href="#TOC"
  ><span class="header-section-number"
    >5.3.2</span
    > Script step</a
  ></h3
><p
>Execute the supplied shell script content. Optionally, can pass an argument to the script specified in the lower text field.</p
><p
>This is similar to calling the command with <code>dispatch</code>:</p
><pre
><code
  >dispatch [filter-options] --stdin -- args &lt;&lt;EOF 
script content here 
EOF
</code
  ></pre
><h3 id="script-file-step"
><a href="#TOC"
  ><span class="header-section-number"
    >5.3.3</span
    > Script file step</a
  ></h3
><p
>Executes the script file local to the sever to the filtered Node set. Arguments can be passed to the script by specifying them in the lower text field.</p
><p
>This is similar to calling the script file with <code>dispatch</code>:</p
><pre
><code
  >dispatch [filter-options] -s scriptfile -- args
</code
  ></pre
><h3 id="job-reference-step"
><a href="#TOC"
  ><span class="header-section-number"
    >5.3.4</span
    > Job reference step</a
  ></h3
><p
>To call another saved Job, create a Job Reference step. Enter the name of the Job and its group.</p
><p
>The Job Reference form provides a Job browser to make it easier to select from the existing set of saved Jobs. Click the &quot;Choose A Job...&quot; link and navigate to the desired Job.</p
><p
>Finally, if the Job defines Options, you can specify them in the commandline arguments text field.</p
><p
>This is simililar to calling the other Job with <code>run</code>:</p
><pre
><code
  >dispatch [filter-options] -j group/jobname
</code
  ></pre
><h2 id="reordering-steps"
><a href="#TOC"
  ><span class="header-section-number"
    >5.4</span
    > Reordering steps</a
  ></h2
><p
>The order of the Workflow steps can be modified by hovering over any step and then clicking and dragging the double arrow icon to the desired position. A blue horizontal bar helps highlight the position where the Job will land.</p
><p
>After releasing the select Job, it will land in the desired position and the step order will be updated.</p
><p
>If you wish to Undo the step reordering, press the &quot;Undo&quot; link above the steps.</p
><p
>The &quot;Redo&quot; button can be pressed to reapply the last undone change.</p
><p
>Press the &quot;Revert All Changes&quot; button to go back to the original step order.</p
><h2 id="save-the-changes"
><a href="#TOC"
  ><span class="header-section-number"
    >5.5</span
    > Save the changes</a
  ></h2
><p
>Once the Workflow steps have been defined and order, changes are permanently saved after pressing the &quot;Create&quot; button if new or the &quot;Update&quot; button if the Job is being modified.</p
><h2 id="summary-3"
><a href="#TOC"
  ><span class="header-section-number"
    >5.6</span
    > Summary</a
  ></h2
><p
>At this point you should understand what a Job workflow is, the kinds of steps they can contain and how to define a workflow.</p
><p
>Next, we'll cover more about RunDeck's Job Option features.</p
><p
>% RUNDECK(1) RunDeck User Manuals | Version 1.0 % Alex Honor % November 20, 2010</p
><h1 id="job-options"
><a href="#TOC"
  ><span class="header-section-number"
    >6</span
    > Job Options</a
  ></h1
><p
>Any command or script can be wrapped as a Job. Creating a Job for every use case will proliferate a large number of Jobs differing only by how the Job jobs calls the scripts. These differences are often environment or application version related. Other times only the person running the Job can provide the needed information to run the Job correctly.</p
><p
>By making your scripts and commands data driven, will make them more generic and therefore, resuable in different contexts. Rather than maintain variations of the same basic process, letting Jobs be driven by a model of options from externally provided data will lead to better abstraction and encapsulation of your process.</p
><p
>RunDeck Jobs can be configured to prompt a user for input by defining one or more named <em
  >options</em
  >. An <em
  >option</em
  > models a named parameter that can be required or optional and include a range of choices that will be presented to the user when the Job is run.</p
><p
>Users supply options by typing in a value or selecting from a menu of choices. A validation pattern ensures input complies to the option requirement. Once chosen, the value chosen for the option is accessible to the commands called by the Job.</p
><p
>Option choices can be modeled as a static set or from a dynamic source. Static choices can be modeled as a comma separated list in the job definition. When option values must be dynamic, the Job can be defined to use a URL to retrieve option data from an external source. Enabling Jobs to access external sources via URL opens the door to integrating RunDeck with other tools and incorporating their data into Job workflows.</p
><h2 id="prompting-the-user"
><a href="#TOC"
  ><span class="header-section-number"
    >6.1</span
    > Prompting the user</a
  ></h2
><p
>The obvious effect from defining Job options is their appearance to the user running the Job. Users will be presented a page called &quot;Choose Execution Options...&quot; where input and menu choices must be configured.</p
><p
>Command line users executing Jobs via the <code>run</code> shell tool also will specify options as an argument string.</p
><p
>It is worth spending a moment to consider how options become part of the user interface to Jobs and give some thought to this next level of procedure formalization.</p
><ul
><li
  >Naming and description convention: Visualize how the user will read the option name and judge its purpose from the description you supply.</li
  ><li
  >Required options: Making an option required means the Job will fail if a user leaves it out.</li
  ><li
  >Input restrictions and validation: If you need to make the option value be somewhat open ended consider how you can create safeguards to control their choice.</li
  ></ul
><h2 id="options-editor"
><a href="#TOC"
  ><span class="header-section-number"
    >6.2</span
    > Options editor</a
  ></h2
><p
>Options can be created for any stored Job. The Job edit page contains an area displaying a summary to existing options and a link to add new ones or edit existing ones.</p
><p
>The option summary shows each option and its default value if it defines them.</p
><p
>Clicking the &quot;edit&quot; link opens up the options editor.</p
><p
>The options editor displays an expanded summary for each defined option. Each option is listed with its usage summary, description, values list and any restrictions. Pressing the &quot;Add an option&quot; link will open a form to define a new parameter. Pressing the &quot;Close&quot; link will collapse the options editor and return back to the summary view.</p
><p
>Moving the mouse over any row in the options editor reveals links to delete or edit the highlighted option. Pressing the remove icon will display a prompt confirming you want to delete that option from the Job. Clicking the &quot;edit&quot; link opens a new form that lets you modify all aspects of that option.</p
><p
>Options can also be defined as part of an XML job definition and later loaded to the RunDeck server. See &quot;job-v10(1)&quot; and &quot;rd-jobs(1)&quot; manual pages if you prefer using an XML Job definition.</p
><h2 id="defining-an-option"
><a href="#TOC"
  ><span class="header-section-number"
    >6.3</span
    > Defining an option</a
  ></h2
><p
>New options can be defined by pressing the &quot;Add an option&quot; link while existing ones can be changed by pressing their &quot;edit&quot; link.</p
><p
>The option definition form is organized into several areas:</p
><dl
><dt
  >Identification</dt
  ><dd
  ><p
    >Here you provide the option's name and description. The name becomes part of acceptable arguments to the Job while the description will be provided as help text to users running the Job.</p
    ></dd
  ><dt
  >Allowed values</dt
  ><dd
  ><p
    >Allowed values provide a model of possible choices. This can contain a static list of values or a URL to a server providing option data. Values can be specified as a comma separated list as seen above but can also be requested from an external source using a &quot;remote URL&quot; <a href="#remote-option-values"
      >See below</a
      >.</p
    ></dd
  ><dt
  >Restrictions</dt
  ><dd
  ><p
    >Defines criteria on which input to accept or present. Option choices can be controlled using the &quot;Enforced from values&quot; restriction. When set &quot;true&quot;, RunDeck will only present a popup menu. If set &quot;false&quot;, a text field will also be presented. Enter a regular expression in the &quot;Match Regular Expression&quot; field the Job will evaluate when run.</p
    ></dd
  ><dt
  >Requirement</dt
  ><dd
  ><p
    >Indicates if the Job can only run if a choice is provided for that Option. Choosing &quot;No&quot; states the option is not required Choose &quot;Yes&quot; to state the option is required.</p
    ></dd
  ></dl
><p
>Once satisfied with the option definition, press the &quot;Save&quot; button to add it to the Job definition. Pressing the &quot;Cancel&quot; button will dismiss the changes and close the form.</p
><h2 id="option-valuesurl"
><a href="#TOC"
  ><span class="header-section-number"
    >6.4</span
    > Option valuesUrl</a
  ></h2
><p
>A model of option values can be retrieved from an external source. When the &quot;valuesUrl&quot; is specified for an Option, then the model of allowed values is retrieved from the specified URL.</p
><p
>File URL scheme is also acceptable (e.g, file:///path/to/job/options/optA.json).</p
><p
>The value data must be returned in JSON data format described below.</p
><h3 id="json-format"
><a href="#TOC"
  ><span class="header-section-number"
    >6.4.1</span
    > JSON format</a
  ></h3
><p
>Two styles of return data are supported: simple list and a name value list.</p
><p
><em
  >Examples</em
  ></p
><p
>Simple List:</p
><pre
><code
  >[&quot;x value for test&quot;,&quot;y value for test&quot;]
</code
  ></pre
><p
>This will populate the select menu with the given values.</p
><p
>Name Value List:</p
><pre
><code
  >[
  {&quot;X Label&quot;:&quot;x value&quot;},
  {&quot;Y Label&quot;:&quot;y value&quot;},
  {&quot;A Label&quot;:&quot;a value&quot;}
] 
</code
  ></pre
><p
>The above will present, in order, the element name, but the corresponding value will be used in the option.</p
><h3 id="variable-expansion-in-remote-urls"
><a href="#TOC"
  ><span class="header-section-number"
    >6.4.2</span
    > Variable expansion in remote URLs</a
  ></h3
><p
>The URL declared for the &quot;valuesUrl&quot; can embed variables which will be filled with certain job context items when making the remote request. This helps make the URLs more generic and contextual to the Job.</p
><p
>Two types of expansions are available, Job context, and Option context.</p
><p
>To include job information in the URL, specify a variable of the form ${job.<em
  >property</em
  >}.</p
><p
>Properties available for Job context:</p
><ul
><li
  >name: Name of the Job</li
  ><li
  >group: Group of the Job</li
  ><li
  >description: Job description</li
  ><li
  >project: Project name</li
  ><li
  >argString: Default argument string for a job</li
  ></ul
><p
>To include Option information in the URL, specify a variable of the form ${option.<em
  >property</em
  >}:</p
><p
>Properties available for Option context:</p
><ul
><li
  >name: Name of the current option</li
  ></ul
><p
><em
  >Examples</em
  ></p
><pre
><code
  >valuesUrl=&quot;http://server.com/test?name=${option.name}&quot;
</code
  ></pre
><p
>Passes the option name as the &quot;name&quot; query parameter to the URL.</p
><pre
><code
  >valuesUrl=&quot;http://server.com/test?jobname=${job.name}&amp;jobgroup=${job.group}&quot;
</code
  ></pre
><p
>Passes the job name and group as query parameters.</p
><h3 id="remote-request-failures"
><a href="#TOC"
  ><span class="header-section-number"
    >6.4.3</span
    > Remote request failures</a
  ></h3
><p
>If the request for the remote option values fails, then the GUI form will display a warning message:</p
><blockquote
><p
  >failed loading remote option values</p
  ></blockquote
><p
>In this case, the option will be allowed to use a textfield to set the value.</p
><h2 id="script-usage"
><a href="#TOC"
  ><span class="header-section-number"
    >6.5</span
    > Script usage</a
  ></h2
><p
>Option values can be passed to scripts as an argument or referenced inside the script via a named token. Option values can be accessed in one of several ways:</p
><dl
><dt
  >Value passed as an environment variable:</dt
  ><dd
  ><p
    >Bash: $RD_OPTION_<em
      >NAME</em
      > <sup
      ><a href="#fn1" class="footnoteRef" id="fnref1"
	>1</a
	></sup
      ></p
    ></dd
  ><dt
  >Value passed as an argument to a script:</dt
  ><dd
  ><p
    >Commandline Arguments: ${option.<em
      >name</em
      >}</p
    ></dd
  ><dt
  >Value referenced as a replacement token inside the script:</dt
  ><dd
  ><p
    >Script Content: @option.<em
      >vip</em
      >@</p
    ></dd
  ></dl
><p
>A single example helps illustrate these methods. Imagine a trivial script is wrapped in a Job named &quot;hello&quot; and has an option named &quot;message&quot;. The &quot;hello&quot; Job option signature would be &quot;-message &lt;&gt;&quot;. Here's the content of this simple script.</p
><pre class="bash"
><code
  >    #!/bin/sh    
    echo envvar=$RD_OPTION_MESSAGE ;# read from environment
    echo args=$1                   ;# comes from argument vector
    echo message=@option.message@  ;# replacement token
</code
  ></pre
><p
>When the user runs the &quot;hello&quot; job they will be prompted for the &quot;message&quot; value. Let's assume they type the word &quot;hello&quot; in response. The output of the Job will be:</p
><pre
><code
  >envar=hello
args=hello    
message=hello    
</code
  ></pre
><p
>It's important to know what happens if the option isn't set. This can happen if you define an option that is not required and do not give it a default value.</p
><p
>Let's imagine the Job was run without a message option supplied, the output would look like this:</p
><pre
><code
  >envar=
args=
message=@option.message@
</code
  ></pre
><p
>Here are some tips to deal with this possibility:</p
><dl
><dt
  >Environment variable:</dt
  ><dd
  ><p
    >As a precaution you might test existence for the variable and perhaps set a default value. To test its existence you might use:</p
    ><pre
    ><code
      > test -s  $RD_OPTION_NAME
</code
      ></pre
    ><p
    >You might also use a Bash feature that tests and defaults it to a value:</p
    ><pre
    ><code
      > ${RD_OPTION_NAME:=mydefault} 
</code
      ></pre
    ></dd
  ><dt
  >Replacement token</dt
  ><dd
  >If the option is unset the token will be left alone inside the script. You might write your script a bit more defensively and change the implementation like so:</dd
  ></dl
><pre class="bash"
><code
  >        message=@option.message@
        if [ &quot;$message&quot; == &quot;@option.message@&quot; ] ; then
           message=mydefault
        fi 
</code
  ></pre
><h2 id="calling-a-job-with-options"
><a href="#TOC"
  ><span class="header-section-number"
    >6.6</span
    > Calling a Job with options</a
  ></h2
><p
>Jobs can be invoked from the command line using the <code>run</code> shell tool or as a step in another Job's workflow.</p
><p
>Using the <code>run</code> command pass them after the double hyphen:</p
><pre
><code
  >run -j jobId -- -paramA valA -paramB valB
</code
  ></pre
><p
>Inside an XML definition, insert them as an <code>arg</code> element:</p
><pre class="xml"
><code
  >&lt;command&gt;
    &lt;jobref group=&quot;test&quot; name=&quot;other tests&quot;&gt;
        &lt;arg line=&quot;-paramA valA -paramB valB&quot;/&gt;
    &lt;/jobref&gt;
&lt;/command&gt;
</code
  ></pre
><p
>Consult the &quot;run(1)&quot; and &quot;job-v20(1)&quot; manual pages for additional information.</p
><h2 id="summary-4"
><a href="#TOC"
  ><span class="header-section-number"
    >6.7</span
    > Summary</a
  ></h2
><p
>After reading this chapter you should understand how to run Jobs with options, as well as, add and edit them.</p
><p
>% RUNDECK(1) RunDeck User Manuals | Version 1.0 % Alex Honor % November 20, 2010</p
><h1 id="authorization-1"
><a href="#TOC"
  ><span class="header-section-number"
    >7</span
    > Authorization</a
  ></h1
><p
>!!!! TODO !!!!</p
><h2 id="summary-5"
><a href="#TOC"
  ><span class="header-section-number"
    >7.1</span
    > Summary</a
  ></h2
><p
>% RUNDECK(1) RunDeck User Manuals | Version 1.0 % Alex Honor % November 20, 2010</p
><h1 id="rundeck-by-example"
><a href="#TOC"
  ><span class="header-section-number"
    >8</span
    > RunDeck by example</a
  ></h1
><p
>This chapter presents working examples reflecting a variety of solutions you can create with RunDeck. Helping you to apply concepts and features introduced in earlier chapters is the focus of these examples. Rather than make the examples abstract, they are set in the context of Acme Anvils, a fictious organization that manages an online application.</p
><h2 id="acme-anvils"
><a href="#TOC"
  ><span class="header-section-number"
    >8.1</span
    > Acme Anvils</a
  ></h2
><p
>Acme Anvils is a hypothetical start up selling new and used anvils from their web site. Two teams inside the company are involved with the development and support of the anvil sales application. Being a new company, there isn't much control over access to the live environment. Either team can make changes to systems which has led to mistakes and outages. Because the senior management is so enthusiastic, they push the teams to deliver new features as frequently as possible. Unfortunately, this has led to another problem: the Acme Anvil web site is an unstable memory hog and requires occassional restarts.</p
><p
>There are actually two methods to the restart procedure depending on the problem: &quot;kill&quot; versus &quot;normal&quot;. The &quot;kill&quot; restart is required when the application becomes totally unresponsive. The &quot;normal&quot; restart occurs when the application needs to free memory.</p
><p
>Depending on the urgency or the staff on hand, either a developer or an administrator conducts the restart, albeit differently. Because the developers write the software, they understand the restart requirements from an application perspective. The administrators on the other hand, are not always informed of these requirements but are well versed in restarting the application from a systems perspective. This has led to a divergence in procedures and has become the main source of problems that affect their customers.</p
><p
>An administrator, tired of the late night calls to restart the application, and frustrated by the knowledge gap between operations and development has decided to take the initiative come up with a better approach.</p
><h2 id="rundeck-set-up"
><a href="#TOC"
  ><span class="header-section-number"
    >8.2</span
    > RunDeck set up</a
  ></h2
><p
>The administrator chooses a machine with access to the servers in the live environment and installs the RunDeck software there.</p
><p
>A project called &quot;anvils&quot; is created to manage the application support activites.</p
><p
>The administrator creates the project using the <code>rd-project</code> shell tool (though this could be done with the RunDeck GUI). After logging into the RunDeck server, the command is run:</p
><pre
><code
  >rd-project -p anvils -a create
</code
  ></pre
><p
>This initialized the &quot;anvils&quot; project in RunDeck so it only contains information about the server node. Adding information about the nodes deployed in the live environment is the next step. The environment has five nodes: anv1-anv5. Anvils is a three tier application and has web, application and database components installed across the five nodes.</p
><p
>Additionally, the administrator decides to incorporate a recent convention to use different system logins to execute SSH commands to control running application components. The web component are run as the &quot;www&quot; user while the app and database components run as user &quot;anvils&quot;.</p
><p
>With this information in hand, the administrator prepares the project resource model using an XML file. The file listing below contains the node definitions for the five nodes - anv1, anv2, anv3, anv4, anv5:</p
><p
>File listing: resources.xml</p
><pre
><code
  >&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE project PUBLIC &quot;-//DTO Labs Inc.//DTD Resources Document 1.0//EN&quot; &quot;project.dtd&quot;&gt;

&lt;project&gt;
  &lt;node name=&quot;anv1&quot; type=&quot;Node&quot;
     description=&quot;an anvils web server&quot; 
     hostname=&quot;anv1.acme.com&quot;  username=&quot;www&quot; tags=&quot;web&quot;/&gt;
  &lt;node name=&quot;anv2&quot; type=&quot;Node&quot; 
     description=&quot;an anvils web server&quot; 
     hostname=&quot;anv2.acme.com&quot;  username=&quot;www&quot; tags=&quot;web&quot;/&gt;
  &lt;node name=&quot;anv3&quot; type=&quot;Node&quot; 
     description=&quot;an avnils app server&quot; 
     hostname=&quot;anv3.acme.com&quot;  username=&quot;anvils&quot; tags=&quot;app&quot;/&gt;
  &lt;node name=&quot;anv4&quot; type=&quot;Node&quot; 
     description=&quot;an anvils app server&quot; 
     hostname=&quot;anv4.acme.com&quot;  username=&quot;anvils&quot; tags=&quot;app&quot;/&gt;
  &lt;node name=&quot;anv5&quot; type=&quot;Node&quot; 
     description=&quot;the anvils database server&quot; 
     hostname=&quot;anv5.acme.com&quot;  username=&quot;anvils&quot; tags=&quot;db&quot;/&gt; 
&lt;/project&gt;
</code
  ></pre
><p
>Reviewing the XML content one sees the XML tag set represent the host information described above. A logical name for each node is defined with the <code>name</code> attribute (eg name=&quot;anv1&quot;). The address used by SSH is set with <code>hostname</code> (eg hostname=&quot;anv1.acme.com&quot;) while the login used to execute SSH commands has been specified with the <code>username</code> attribute (username=&quot;www&quot; vs username=&quot;anvils&quot;). The value for the <code>tags</code> attribute reflects the node function (tags=&quot;web&quot; vs tags=&quot;app&quot;).</p
><p
>The administrator saves the file and places it in a path of his choice. To make RunDeck aware of it, the administrator modifies the project configuration file, $RDECK_BASE/projects/anvils/etc/project.properties, modifying the <code>project.resources.file</code> setting :</p
><pre
><code
  >project.resources.file = /etc/rundeck/projects/anvils/resources.xml
</code
  ></pre
><p
>With the resources file in place and the project configuration updated, the administrator has finished with the resource model preparation and can begin dispatching commands.</p
><h2 id="tag-classification-and-command-dispatching"
><a href="#TOC"
  ><span class="header-section-number"
    >8.3</span
    > Tag classification and command dispatching</a
  ></h2
><p
>With tags that describe application role, commands can be targeted to specific sub sets of nodes without hard coding any hostnames. The <code>dispatch</code> command's listing feature illustrates how tag filtering selects particular node sets in the shell:</p
><p
>Use the <code>tags</code> keyword to list the web nodes:</p
><pre
><code
  >dispatch -p anvils -I tags=web
anv1 anv2
</code
  ></pre
><p
>List the app nodes:</p
><pre
><code
  >dispatch -p anvils -I tags=app
anv3 anv4
</code
  ></pre
><p
>List the db nodes:</p
><pre
><code
  >dispatch -p anvils -I tags=db
anv5
</code
  ></pre
><p
>Use the &quot;+&quot; (AND) operator to list the web and app nodes:</p
><pre
><code
  >dispatch -p anvils -I tags=web+app
anv1 anv2 anv3 anv4
</code
  ></pre
><p
>Exclude the web and app nodes:</p
><pre
><code
  >dispatch -p anvils -X tags=web+app
anv5
</code
  ></pre
><p
>Using a wildcard for node name, list all the nodes:</p
><pre
><code
  >dispatch -p anvils -I '.*' 
anv1 anv2 anv3 anv4 anv5 
</code
  ></pre
><p
>Filtering with tags provides an abstraction over hostnames and lets the administrator think about scripting process using loose classifications. New nodes can be added, others decommissioned while others given new purpose, and the procedures stay unchanged because they are bound to the filtering critera.</p
><p
>This simple classification scheme will allow the developers and administrators to share a common vocabulary when talking about the kinds of nodes supporting the Anvils application.</p
><h2 id="jobs-1"
><a href="#TOC"
  ><span class="header-section-number"
    >8.4</span
    > Jobs</a
  ></h2
><p
>Jobs are a convenient method to establish a library of routine procedures. By its nature, a saved Job encapsulates a process into a logically named interface. Jobs can begin as a single item workflow that calls a small or large shell script but evolve into a multi-step workflow. One job can also call another job as a step in its workflow. Using this approach one can view each Job as a reusable building block upon which more complex automation can be built.</p
><p
>The administrator decides Jobs can be used to encapsulate procedures to manage the restart process. Both developers and administrators can collaborate on their definition and evolution and maintenance.</p
><p
>Two sets of scripts are already in use to manage the startup and shutdown procedures. Rather than force the issue as to which one is correct or superior, the administrator focuses on creating a skeleton to more easily present how scripts can be encapsulated by the job workflow. After demonstrating this simple framework, the administrator can discuss how to incorporate the best of both script implementations into the Job definitions.</p
><p
>For the skeleton, the administrator creates simple placeholder scripts that merely echo their intent and the arguments passed to the them. Two scripts - start.sh and stop.sh - represent the two steps of the restart process.</p
><p
>Scripts:</p
><p
>File listing: start.sh</p
><pre
><code
  >#!/bin/sh
# Usage: $0 
echo Web started.
</code
  ></pre
><p
>File listing: stop.sh</p
><pre
><code
  >#!/bin/sh
# Usage: $0 [normal|kill]
echo Web stopped with method: $1.
</code
  ></pre
><p
>Because either the normal or kill can be specified for the &quot;method&quot; option, the Jobs will need to pass the user's choice as an argument to the script.</p
><p
>There is no script for the restart process itself since that will be defined as a Job workflow.</p
><h3 id="job-structure"
><a href="#TOC"
  ><span class="header-section-number"
    >8.4.1</span
    > Job structure</a
  ></h3
><p
>With an idea of the restart scripts in mind, the next step is to define a job to encapsulate the restart procedure. Though the overall goal is to provide a single restart procedure, for the sake of reusability, it might be preferred to break each step of the process into separate jobs.</p
><p
>Using this approach the adminstrator imagines the following jobs:</p
><ul
><li
  >start: call the start.sh script to start the web service</li
  ><li
  >stop: call the stop.sh script to stop the web service</li
  ><li
  >Restart: calls the jobs: stop, start</li
  ></ul
><p
>Since the restart procedure is the primary focus, it is capitalized for distinction.</p
><p
>The extra complexity from defining a job for every individual step can pay off later, if those steps can be recombined with future jobs to serve later management needs. How far a process is decomposed into individual jobs is a judgement balancing maintenance requirements and the desire for job reuse.</p
><h3 id="job-grouping"
><a href="#TOC"
  ><span class="header-section-number"
    >8.4.2</span
    > Job grouping</a
  ></h3
><p
>Though not a requirement, it is helpful to use job groups and have a convention for naming them. A good convention assists others with a navigation scheme that helps them remember and find the desired procedure.</p
><p
>The administrator chooses to create a top level group named &quot;/anvils/web/&quot; where the web restart related jobs will be organized.</p
><pre
><code
  >anvils/
`-- web/
    |-- Restart
    |-- start
    `-- stop
</code
  ></pre
><p
>Users logging into the RunDeck graphical console, will see this grouping of jobs.</p
><h2 id="job-option"
><a href="#TOC"
  ><span class="header-section-number"
    >8.5</span
    > Job option</a
  ></h2
><p
>To support specifying the restart method to the scripts, the the three jobs will declare an option named &quot;method&quot;. Without such a parameter, the administrator would be forced to duplicate restart Jobs for both the kill and normal stop methods.</p
><p
>Another benefit from defining the job option is the ability to display a menu of choices to the user running the job. Once chosen, the value selected by the menu is then passed to the script.</p
><h3 id="allowed-values"
><a href="#TOC"
  ><span class="header-section-number"
    >8.5.1</span
    > Allowed values</a
  ></h3
><p
>An option can be defined to only allow values from a specified list. This places safe guards on how a Job can be run by limiting choices to those the scripts can safely handle.</p
><p
>The administrator takes advantage of this by limiting the &quot;method&quot; option values to just &quot;normal&quot; or &quot;kill&quot; choices.</p
><p
>The screenshot below contains the Option edit form for the &quot;method&quot; option. The form includes elements to define description and default value, as well as, Allowed Values and Restrictions.</p
><p
>Allowed values can be specified as a comma separated list as seen above but can also be requested from an external source using a &quot;remote URL&quot;.</p
><p
>Option choices can be controlled using the &quot;Enforced from values&quot; restriction. When set &quot;true&quot;, the RunDeck UI will only present a popup menu. If set &quot;false&quot;, a text field will also be presented. Use the &quot;Match Regular Expression&quot; form to validate the input option.</p
><p
>Here's a screenshot of how RunDeck will display the VIP menu choices:</p
><h3 id="script-access-to-option-data"
><a href="#TOC"
  ><span class="header-section-number"
    >8.5.2</span
    > Script access to option data</a
  ></h3
><p
>Option values can be passed to scripts as an argument or referenced inside the script using a named token. For example, the value for the &quot;method&quot; option selection can be accessed in one of several ways:</p
><p
>Value referenced as an environment variable:</p
><ul
><li
  >Bash: $CT_OPTION_METHOD</li
  ></ul
><p
>Value passed in the argument vector to the executed script or command via the <code>scriptargs</code> tag:</p
><ul
><li
  >Commandline Arguments: ${option.method}</li
  ></ul
><p
>Value represented as a named token inside the script and replaced before execution:</p
><ul
><li
  >Script Content: @option.method@</li
  ></ul
><h2 id="job-workflow-composition"
><a href="#TOC"
  ><span class="header-section-number"
    >8.6</span
    > Job workflow composition</a
  ></h2
><p
>With an understanding of the scripts and the option needed to control the restart operation, the final step is to compose the Job definitions.</p
><p
>While each job can be defined graphically in RunDeck, each can succinctly be defined using an XML file comforming to the &quot;jobs-v20(1)&quot; document format. This XML document contains a set of tags corresponding to the choices seen in the RunDeck GUI form.</p
><p
>Below are the XML definitions for the jobs. One or more jobs can be defined inside a single XML file but your convention will dictate how to organize the definitions. The files can be named any way desired and do not have to correspond to the Job name or its group.</p
><p
>File listing: stop.xml</p
><pre
><code
  >&lt;joblist&gt;   
    &lt;job&gt; 
       &lt;name&gt;stop&lt;/name&gt;  
       &lt;description&gt;the web stop procedure&lt;/description&gt;  
       &lt;loglevel&gt;INFO&lt;/loglevel&gt;  
       &lt;group&gt;anvils/web&lt;/group&gt;  
       &lt;context&gt; 
           &lt;project&gt;anvils&lt;/project&gt;  
             &lt;options&gt; 
               &lt;option name=&quot;method&quot; enforcedvalues=&quot;true&quot;
                       required=&quot;true&quot; 
                   values=&quot;normal,kill&quot;/&gt; 
               &lt;/options&gt; 
       &lt;/context&gt;  
       &lt;sequence threadcount=&quot;1&quot; keepgoing=&quot;false&quot; strategy=&quot;node-first&quot;&gt; 
         &lt;command&gt; 
           &lt;script&gt;&lt;![CDATA[#!/bin/sh
echo Web stopped with method: $1.]]&gt;&lt;/script&gt;  
            &lt;scriptargs&gt;${option.method}&lt;/scriptargs&gt; 
         &lt;/command&gt; 
       &lt;/sequence&gt;  
       &lt;nodefilters excludeprecedence=&quot;true&quot;&gt; 
         &lt;include&gt; 
          &lt;tags&gt;web&lt;/tags&gt; 
          &lt;/include&gt; 
       &lt;/nodefilters&gt;  
       &lt;dispatch&gt; 
         &lt;threadcount&gt;1&lt;/threadcount&gt;  
         &lt;keepgoing&gt;false&lt;/keepgoing&gt; 
       &lt;/dispatch&gt; 
     &lt;/job&gt;
&lt;/joblist&gt;
</code
  ></pre
><p
>Defines Job, /anvils/web/stop, and executes the shell script to Nodes tagged &quot;web&quot;. Using the <code>scriptargs</code> tag, the shell script is passed a single argument, <code>${option.method}</code>, containing the value chosen in the Job run form.</p
><p
>File listing: start.xml</p
><pre
><code
  >&lt;joblist&gt;   
   &lt;job&gt; 
     &lt;name&gt;start&lt;/name&gt;  
     &lt;description&gt;the web start procedure&lt;/description&gt;  
     &lt;loglevel&gt;INFO&lt;/loglevel&gt;  
     &lt;group&gt;anvils/web&lt;/group&gt;  
    &lt;context&gt; 
      &lt;project&gt;anvils&lt;/project&gt;  
        &lt;options&gt; 
         &lt;option name=&quot;method&quot; enforcedvalues=&quot;true&quot; required=&quot;true&quot; 
          values=&quot;normal,kill&quot; /&gt; 
       &lt;/options&gt; 
    &lt;/context&gt;  
    &lt;sequence threadcount=&quot;1&quot; keepgoing=&quot;false&quot; strategy=&quot;node-first&quot;&gt; 
     &lt;command&gt; 
      &lt;script&gt;&lt;![CDATA[#!/bin/sh
 echo Web started. after a $1 shutdown]]&gt;&lt;/script&gt;  
       &lt;scriptargs&gt;${option.method}&lt;/scriptargs&gt; 
     &lt;/command&gt; 
  &lt;/sequence&gt;  
    &lt;nodefilters excludeprecedence=&quot;true&quot;&gt; 
      &lt;include&gt; 
        &lt;tags&gt;web&lt;/tags&gt; 
      &lt;/include&gt; 
   &lt;/nodefilters&gt;  
   &lt;dispatch&gt; 
     &lt;threadcount&gt;1&lt;/threadcount&gt;  
     &lt;keepgoing&gt;false&lt;/keepgoing&gt; 
   &lt;/dispatch&gt; 
  &lt;/job&gt;
&lt;/joblist&gt;
</code
  ></pre
><p
>Defines Job, /anvils/web/start, that also executes a shell script to Nodes tagged &quot;web&quot;. The shell script is passed a single argument, <code>${option.method}</code>, containing the value chosen in the Job run form.</p
><p
>File listing: restart.xml</p
><pre
><code
  >&lt;joblist&gt;   
   &lt;job&gt; 
     &lt;name&gt;Restart&lt;/name&gt;  
     &lt;description&gt;restart the web server&lt;/description&gt;  
     &lt;loglevel&gt;INFO&lt;/loglevel&gt;  
     &lt;group&gt;anvils/web&lt;/group&gt;  
     &lt;context&gt; 
       &lt;project&gt;anvils&lt;/project&gt;  
         &lt;options&gt; 
           &lt;option name=&quot;method&quot; enforcedvalues=&quot;true&quot; required=&quot;false&quot; 
          values=&quot;normal,kill&quot; /&gt; 
        &lt;/options&gt; 
     &lt;/context&gt;  
     &lt;sequence threadcount=&quot;1&quot; keepgoing=&quot;false&quot; strategy=&quot;node-first&quot;&gt; 
      &lt;command&gt; 
        &lt;jobref name=&quot;stop&quot; group=&quot;apps/web&quot;&gt; 
          &lt;arg line=&quot;-method ${option.method}&quot;/&gt; 
        &lt;/jobref&gt; 
      &lt;/command&gt;  
      &lt;command&gt; 
        &lt;jobref name=&quot;start&quot; group=&quot;apps/web&quot;&gt; 
          &lt;arg line=&quot;-method ${option.method}&quot;/&gt; 
        &lt;/jobref&gt; 
      &lt;/command&gt; 
    &lt;/sequence&gt;  
    &lt;nodefilters excludeprecedence=&quot;true&quot;&gt; 
     &lt;include&gt; 
       &lt;tags&gt;web&lt;/tags&gt; 
     &lt;/include&gt; 
    &lt;/nodefilters&gt;  
     &lt;dispatch&gt; 
       &lt;threadcount&gt;1&lt;/threadcount&gt;  
       &lt;keepgoing&gt;true&lt;/keepgoing&gt; 
     &lt;/dispatch&gt; 
   &lt;/job&gt;   
&lt;/joblist&gt;
</code
  ></pre
><p
>Defines Job, /anvils/web/Restart, that executes a sequence of Job calls, using the <code>jobref</code> tag.</p
><p
>Saving the XML definitions files located on the RunDeck server, one can load them using the <code>rd-jobs</code> command.</p
><p
>Run the <code>rd-jobs load</code> command for each job definition file:</p
><pre
><code
  >rd-jobs load -f start.xml
rd-jobs load -f stop.xml
rd-jobs load -f restart.xml
</code
  ></pre
><p
>The <code>rd-jobs list</code> command queries RunDeck and prints out the list of defined jobs:</p
><pre
><code
  >rd-jobs list
Found 3 jobs:
- Restart [9] &lt;http://strongbad:8080/scheduledExecution/show/9&gt;
- start [10] &lt;http://strongbad:8080/scheduledExecution/show/10&gt;
- stop [11] &lt;http://strongbad:8080/scheduledExecution/show/11&gt;
</code
  ></pre
><p
>Of course, the jobs can be viewed inside RunDeck's UI by going to the Jobs page.</p
><p
>You will see the composition of the &quot;Restart&quot; job as a workflow calling the jobs: stop and start. The &quot;Restart&quot; job passes the &quot;method&quot; option value to the lower level stop and start Jobs.</p
><h2 id="running-the-job"
><a href="#TOC"
  ><span class="header-section-number"
    >8.7</span
    > Running the job</a
  ></h2
><p
>The Jobs can be run from the RunDeck graphical console by going to the &quot;Jobs&quot; page. From there, navigate to the &quot;Anvils/web&quot; job group to display the three stored Jobs.</p
><p
>Clicking the &quot;Run&quot; button for the Restart job, will display the options selection page. The menu for the &quot;method&quot; option dislays the two choices: &quot;normal&quot; and &quot;kill&quot;. No other choices can be made, nor a textfield for free form entry, because the &quot;method&quot; option was defined with the restriction &quot;enforced from allowed values&quot;.</p
><p
>The jobs can also be started from the command line using the <code>run</code> shell tool. The job group and name are specified using the &quot;-j&quot; parameter. Any options the Job supports are supplied after the &quot;--&quot; (double dash) parameter.</p
><p
>Run Restart specifying the method, &quot;normal&quot;:</p
><pre
><code
  >run -j &quot;anvils/web/Restart&quot; -- -method normal
</code
  ></pre
><p
>Run Restart specifying the method, &quot;kill&quot;:</p
><pre
><code
  >run -j &quot;anvils/web/Restart&quot; -- -method kill
</code
  ></pre
><h2 id="job-access-control"
><a href="#TOC"
  ><span class="header-section-number"
    >8.8</span
    > Job access control</a
  ></h2
><p
>Access to running or modifying Jobs is managed in an access control policy defined using the aclpolicy XML format (man &quot;aclpolicy-v10(5)&quot;). This file contains a number of policy elements that describe what user group is allowed to perform which actions.</p
><p
>The administrator wants to use the aclpolicy to define two levels of access. The first level, has limited privilge and allows for just running jobs. The second level, is administrative and can modify job definitions.</p
><p
>Policies can be organized into more than one file to help organize access by group or pattern of use. The normal RunDeck install will define two user groups: admin and deploy and have a generated a policy for the &quot;admin&quot; group.</p
><p
>The Acme administrator decides to create a policy that allows users in the &quot;deploy&quot; group to run commands just in the &quot;anvils&quot; and &quot;anvils/web&quot; Job groups. We can employ the &quot;deploy&quot; login and group as it was also included in the normal install.</p
><p
>To create the aclpolicy file for the &quot;deploy&quot; group:</p
><pre
><code
  >cp $RDECK_BASE/etc/admin.aclpolicy $RDECK_BASE/etc/deploy.aclpolicy
</code
  ></pre
><p
>Modify the <command> and <group> elements as shown in the example below. Notice that just workflow_read,workflow_run actions are allowed.</p
><pre class="xml"
><code
  >$ cat $RDECK_BASE/etc/deploy.aclpolicy
&lt;policies&gt;
  &lt;policy description=&quot;Deploy group access policy.&quot;&gt;
    &lt;context project=&quot;*&quot;&gt;
      &lt;command group=&quot;anvils&quot; job=&quot;*&quot; actions=&quot;workflow_read,workflow_run&quot;/&gt;
      &lt;command group=&quot;anvils/web&quot; job=&quot;*&quot; actions=&quot;workflow_read,workflow_run&quot;/&gt;
    &lt;/context&gt;
    &lt;by&gt;
      &lt;group name=&quot;deploy&quot;/&gt;
    &lt;/by&gt;
  &lt;/policy&gt;
&lt;/policies&gt;
</code
  ></pre
><p
>Restart jetty so RunDeck loads the new policy file.</p
><pre
><code
  >jetty.sh restart
</code
  ></pre
><p
>Once the RunDeck webapp has started, login as the &quot;deploy&quot; user (the password is probably &quot;deploy&quot;). Just the Jobs in the &quot;anvils&quot; group are displayed in the Jobs page. The &quot;deploy&quot; user does is not allowed to access jobs outside of &quot;/anvils group.</p
><p
>Notice the absence of the &quot;New Job&quot; button that would be displayed if logged in as &quot;admin&quot;. Job creation is an action not granted to &quot;deploy&quot;. Notice also, that the button bar for the listed Jobs does not include icons for editing or deleting the Job. Only workflow_read and workflow_actions were allowed in the deploy.aclpolicy file.</p
><h2 id="resource-model-provider"
><a href="#TOC"
  ><span class="header-section-number"
    >8.9</span
    > Resource model provider</a
  ></h2
><p
>RunDeck dispatches commands to the nodes defined in the project resource model stored in an XML file. A RunDeck project can also be configured to retrieve this file from a <em
  >resource model provider</em
  > via URL and store the data locally.</p
><p
>A <em
  >resource model provider</em
  > is an external service that is accesible via HTTP GET method returning data conforming to the RunDeck resources document format (resource-v10(5)). This allows RunDeck projects to obtain node information from other tools or data sources. To configure a resource model provider, the <code>project.resource.url</code> setting must be configured.</p
><p
>Earlier in the <a href="#rundeck-set-up"
  >RunDeck set up</a
  > section, the anvils project resource model was defined using an XML file located on the server. As node information changes, this file will need to be edited in place. Since it's just a file local to the server, nothing controls versioning and so won't have a log of changes. A better alternative would be to implement a resource model provider.</p
><h3 id="simple-scm-resource-model-provider"
><a href="#TOC"
  ><span class="header-section-number"
    >8.9.1</span
    > Simple SCM resource model provider</a
  ></h3
><p
>Putting the resources.xml file under the control of a source code management tool is a simple solution to controlling and tracking change. Any changes will be committed and the commit messages become an audit log. Most source code management tools provide a web interface to retrieve file revisions based on a URL and thus make it accessible as a resource model provider.</p
><p
>The Acme administrator decides this approach is a good first step to control versioning for the anvils resource model. Acme is a subversion user and installed &quot;viewvc&quot; to give web access to the repository.</p
><p
>First, the current resources.xml is added to the repsotitory and committed:</p
><pre
><code
  >svn add resources.xml http://svn.acme.com/ops/anvils/resources.xml
svn commit -m &quot;added resource model for anvils&quot; resources.xml
</code
  ></pre
><p
>To test access, the administrator downloads the latest revision (ie, &quot;HEAD&quot;) via the &quot;viewvc&quot; interface.</p
><pre
><code
  > curl http://svn.acme.com/viewvc/ops/anvils/resources.xml?revision=HEAD
</code
  ></pre
><p
>Next, the anvils project.properties configuration file is modified to reference the URL to retrieve the &quot;HEAD&quot; revision:</p
><pre
><code
  >project.resources.file = /etc/rundeck/projects/anvils/resources.xml
project.resources.url  = http://svn.acme.com/viewvc/ops/anvils/resources.xml?revision=HEAD
</code
  ></pre
><p
>This configuration specifies the anvils resource model will be retrieved from <code>project.resources.url</code> and then stored at <code>project.resources.file</code>. Now, anytime RunDeck refreshes the anvils resource model, it will request the resources.xml file from the viewvc URL, obtaining the latest revision.</p
><h3 id="editable-resource-model-providers"
><a href="#TOC"
  ><span class="header-section-number"
    >8.9.2</span
    > Editable resource model providers</a
  ></h3
><p
>Some teams have acquired or developed tools to manage information about the hosts deployed in their networks. These tools have interfaces to not just view but also modify the data about these hosts. Though there is no widely used common standard adopted by users of these tools, it is possible to map the data to meet the needs of RunDeck resource models. The resource model document format is quite simple and the required data really comes down to defining: node, hostname, username and tags. Abitrary key value pair data can be mapped to the <code>setting</code> tag and then associated to the relevant nodes using the <code>resources</code> element.</p
><p
>As a matter of convenience for graphical console users, the RunDeck resource model document format provides two attributes belonging to the <code>node</code> tag that help connect the dots between the RunDeck UI and the editing interface provided by the external data management tool.</p
><dl
><dt
  ><em
    >editUrl</em
    ></dt
  ><dd
  ><p
    >Define the value for the <em
      >editUrl</em
      > attribute to reference a link to the corresponding data entity in the data management tool. The RunDeck graphical console will generate a link for users browsing the detail for that node. Clicking that link will open a new browser window to that URL.</p
    ></dd
  ><dt
  ><em
    >remoteUrl</em
    ></dt
  ><dd
  ><p
    >Define the value for the <em
      >remoteUrl</em
      > attribute to reference a link to an HTML page that will be embedded as an IFRAME inside the node view of the RunDeck graphical console. Clicking this link will cause an AJAX request to the specified URL and display the results inside the RunDeck page. After users are finished with the external editing form, they press close.</p
    ></dd
  ></dl
><h4 id="rightscale-resource-model-provider"
><a href="#TOC"
  ><span class="header-section-number"
    >8.9.2.1</span
    > RightScale resource model provider</a
  ></h4
><p
>RightScale provides a management layer for the Amazon EC2 cloud service and acts as a life cycle manager for virtual hosts. It provides an API that returns XML data about the hosts managed in your deployments. The data in this XML can be mapped to a RunDeck resource model via a simple transformation process.</p
><p
>The hypothetical Acme Anvils hosts are actually EC2 servers maintained with RightScale. Additionally, the administrator does not want to hand edit the resources.xml file everytime nodes are decomissioned or there is a scaling event which instantiates new servers. He decides a better approach would be to create a resource model provider that will use the RightScale API and transform the results to meet RunDeck's needs. Finally, the administrator decides to utilize the <code>editUrl</code> attribute to provide a web link back to the RightScale user interface. This way, when he browses the Nodes he can click on the link to get back to that server configuration in RightScale.</p
><p
>The basic technical requirements to accomplish the the resource model can be achived by a CGI script that</p
><ul
><li
  >creates a session specifying the RightScale account credentials</li
  ><li
  >use the api to query for the server info for the Acme deployment</li
  ><li
  >iterate over the results and generate the resources.xml</li
  ></ul
><p
>These steps can be done with cUrl and xmlstarlet</p
><p
>... show CGI script listing ...</p
><h4 id="custom-database-resource-model-provider"
><a href="#TOC"
  ><span class="header-section-number"
    >8.9.2.2</span
    > Custom database resource model provider</a
  ></h4
><p
>... Acme matures a bit and builds its own datacenter and a custom cmdb...</p
><p
>... example shows use remote html form via remoteUrl and ajax protocol...</p
><h2 id="option-model-provider"
><a href="#TOC"
  ><span class="header-section-number"
    >8.10</span
    > Option model provider</a
  ></h2
><p
>A simple method to integrate information from other tools is via an options model provider. An <em
  >options model provider</em
  > is an external service that returns a model of option values RunDeck loads when a user runs a Job. Options model providers must return their data as a list of key value pairs formatted in JSON.</p
><p
>The following two sections describe examples using simple CGI scripts that act as option model providers.</p
><h3 id="hudson-artifacts-option-provider"
><a href="#TOC"
  ><span class="header-section-number"
    >8.10.1</span
    > Hudson artifacts option provider</a
  ></h3
><p
>An end-to-end release process often requires obtaining build artifacts and publishing them to a central repository for later distribution. A continuous integration server like Hudson makes identifying the build artifacts a simple Job configuration step. Hudson proivdes a network API to obtain the list of artifacts from successful builds via a simple HTTP GET request.</p
><p
>Acme builds its artifacts as RPMs and has confiugred their build job to identify them. The operations team wants to create Jobs that would allow them to choose a version of these artifacts generated by the automated build.</p
><p
>A simple CGI script that requests the information from Hudson and then generates a JSON document is sufficient to accomplish this. The CGI script can use query paramaters to specify the Hudson server, hudson job and artifact path. Job writers can then specify the paramaterized URL to the CGI script to obtain the artifacts list as an options model and present the results as a menu to Job users.</p
><p
>The code listing below shows the the CGI script essentially does a call to the <code>cUrl</code> command to retreive the XML document containing the artifacts information and then parses it using <code>xmlstarlet</code>.</p
><p
>File listing: hudson-artifacts.cgi</p
><pre
><code
  >#!/bin/bash
# Requires: curl, xmlstarlet
# Returns a JSON list of key/val pairs
#
# Query Params and their defaults
hudsonUrl=https://build.acme.com:8080/job
hudsonJob=ApplicationBuild
artifactPath=/artifact/bin/dist/RPMS/noarch/

echo Content-type: application/json
echo &quot;&quot;
for VAR in `echo $QUERY_STRING | tr &quot;&amp;&quot; &quot;\t&quot;`
do
  NAME=$(echo $VAR | tr = &quot; &quot; | awk '{print $1}';);
  VALUE=$(echo $VAR | tr = &quot; &quot; | awk '{ print $2}' | tr + &quot; &quot;);
  declare $NAME=&quot;$VALUE&quot;;
done

curl -s -L -k $hudsonUrl/${hudsonJob}/api/xml?depth=1 | \
  xmlstarlet sel -t -o &quot;{&quot; \
    -t -m &quot;//build[result/text()='SUCCESS']&quot; --sort A:T:L number  \
    -m . -o &quot;&amp;quot;Release&quot; -m changeSet/item -o ' ' -v revision -b \
    -m . -o &quot;, Hudson Build &quot; -v number -o &quot;&amp;quot;:&quot; \
    -m 'artifact[position() = 1]' -o &quot;&amp;quot;&quot; -v '../number' -o $artifactPath -o &quot;{&quot; -b \
    -m 'artifact[position() != last()]' -v 'fileName' -o &quot;,&quot; -b \
    -m 'artifact[position() = last()]' -v 'fileName' -o &quot;}&amp;quot;,&quot; \
    -t -o &quot;}&quot;
</code
  ></pre
><p
>After deploying this script to a CGI enabled directory on the operations web server, it can be tested directly by requesting it using cUrl.</p
><pre
><code
  >curl -d hudsonJob=anvils&amp;artifactPath=/artifact/bin/dist/RPMS/noarch/&quot; \
    --get http://opts.acme.com/cgi/hudson-artifacts.cgi
</code
  ></pre
><p
>The server response should return JSON data resembling the example below:</p
><pre
><code
  >[ 
  {&quot;anvils-1.1.rpm&quot;:&quot;/artifact/bin/dist/RPMS/noarch/anvils-1.1.rpm&quot;}, 
  {&quot;anvils-1.2.rpm&quot;:&quot;/artifact/bin/dist/RPMS/noarch/anvils-1.2.rpm&quot;} 
]   
</code
  ></pre
><p
>Now in place, jobs can request this option data like so:</p
><pre
><code
  > &lt;option name=&quot;method&quot; enforcedvalues=&quot;true&quot; required=&quot;true&quot; 
      valuesUrl=&quot;http://ops.acme.com/cgi/hudson-artifacts.cgi?hudsonJob=anvils&quot;/&gt; 
</code
  ></pre
><p
>The RunDeck UI will display the package names in the menu and once selected the Job will have the path to the build artifact on the Hudson server.</p
><h3 id="yum-repoquery-option-model-provider"
><a href="#TOC"
  ><span class="header-section-number"
    >8.10.2</span
    > Yum repoquery option model provider</a
  ></h3
><p
>Yum is a great tool for automating RPM package management. With Yum, administrators can publish packages to the repository and then use the yum client tool to automate the installation of packages along with their declared dependencies. Yum includes a command called <a href="http://linux.die.net/man/1/repoquery"
  >repoquery</a
  > useful for querying Yum repositories similarly to rpm queries.</p
><p
>Acme set up their own Yum repository to distribute application release packages. The Acme administrator wants to provide an option model to Jobs that need to know what packages provide a given capability.</p
><p
>The code listing below shows it is a simple wrapper around the repoquery command that formats the results as JSON data.</p
><p
>File listing: yum-repoquery.cgi</p
><pre
><code
  >#!/bin/bash
# Requires: repoquery
# 
# Query Params and their defaults
repo=acme-staging
label=&quot;Anvils Release&quot;
package=anvils
max=30
#
echo Content-type: application/json
echo &quot;&quot;
for VAR in `echo $QUERY_STRING | tr &quot;&amp;&quot; &quot;\t&quot;`
do
  NAME=$(echo $VAR | tr = &quot; &quot; | awk '{print $1}';);
  VALUE=$(echo $VAR | tr = &quot; &quot; | awk '{ print $2}' | tr + &quot; &quot;);
  declare $NAME=&quot;$VALUE&quot;;
done

echo '{'
repoquery --enablerepo=$repo --show-dupes \
  --qf='&quot;${label} %{VERSION}-%{RELEASE}&quot;:&quot;%{NAME}-%{VERSION}-%{RELEASE}&quot;,' \
  -q --whatprovides ${package} | sort -t - -k 4,4nr | head -n${max}
echo '}'
</code
  ></pre
><p
>After deploying this script to the CGI enabled directory on the operations web server, it can be tested directly by requesting it using cUrl.</p
><pre
><code
  >curl -d &quot;repo=acme&amp;label=Anvils&amp;package=anvils&quot; \
    --get http://ops.acme.com/cgi/yum-repoquery.cgi
</code
  ></pre
><p
>The server response should return JSON data resembling the example below:</p
><pre
><code
  >[
  {&quot;blah&quot;:&quot;val&quot;},
  {&quot;blah&quot;:&quot;val&quot;}
]
</code
  ></pre
><p
>Now in place, jobs can request the option model data like so:</p
><pre
><code
  > &lt;option name=&quot;method&quot; enforcedvalues=&quot;true&quot; required=&quot;true&quot; 
      valuesUrl=&quot;http://ops.acme.com/cgi/yum-repoquery.cgi?package=anvils&quot;/&gt; 
</code
  ></pre
><p
>The RunDeck UI will display the package names in the menu and once selected, the Job will have the matching package versions.</p
><h2 id="summary-6"
><a href="#TOC"
  ><span class="header-section-number"
    >8.11</span
    > Summary</a
  ></h2
><p
>% RUNDECK(1) RunDeck User Manuals | Version 1.0 % Alex Honor % November 20, 2010</p
><h1 id="coordinatation"
><a href="#TOC"
  ><span class="header-section-number"
    >9</span
    > Coordinatation</a
  ></h1
><h2 id="execution-strategies-revisited"
><a href="#TOC"
  ><span class="header-section-number"
    >9.1</span
    > Execution strategies revisited</a
  ></h2
><h3 id="step-vs-node-oriented"
><a href="#TOC"
  ><span class="header-section-number"
    >9.1.1</span
    > Step vs Node oriented</a
  ></h3
><h3 id="topology-structures-tiers-and-slices"
><a href="#TOC"
  ><span class="header-section-number"
    >9.1.2</span
    > Topology structures: Tiers and Slices</a
  ></h3
><h3 id="coordination-models"
><a href="#TOC"
  ><span class="header-section-number"
    >9.1.3</span
    > Coordination models</a
  ></h3
><p
>and job refs</p
><p
>jobs manage different tiers</p
><h4 id="sync-points"
><a href="#TOC"
  ><span class="header-section-number"
    >9.1.3.1</span
    > Sync points</a
  ></h4
><p
>Coordinate with sync points to understand when to continue or not</p
><h2 id="summary-7"
><a href="#TOC"
  ><span class="header-section-number"
    >9.2</span
    > Summary</a
  ></h2
><p
>% RUNDECK(1) RunDeck User Manuals | Version 1.0 % Alex Honor % November 20, 2010</p
><h1 id="administration"
><a href="#TOC"
  ><span class="header-section-number"
    >10</span
    > Administration</a
  ></h1
><h2 id="ssl"
><a href="#TOC"
  ><span class="header-section-number"
    >10.1</span
    > SSL</a
  ></h2
><h2 id="ldap"
><a href="#TOC"
  ><span class="header-section-number"
    >10.2</span
    > LDAP</a
  ></h2
><h2 id="backup-and-recovery"
><a href="#TOC"
  ><span class="header-section-number"
    >10.3</span
    > Backup and recovery</a
  ></h2
><h2 id="high-availability"
><a href="#TOC"
  ><span class="header-section-number"
    >10.4</span
    > High availability</a
  ></h2
><h2 id="configuration"
><a href="#TOC"
  ><span class="header-section-number"
    >10.5</span
    > Configuration</a
  ></h2
><p
>rdeck.base * linux: /etc/rundeck/client * launcher: $RDECK_BASE/etc</p
><p
>for server linux: /etc/rundeck/server (like jetty.home) laucher: $RDECK_BASE/server</p
><h2 id="logs"
><a href="#TOC"
  ><span class="header-section-number"
    >10.6</span
    > Logs</a
  ></h2
><p
>linux: /var/log/rundeck launcher: $RDECK_BASE/var/logs</p
><h2 id="summary-8"
><a href="#TOC"
  ><span class="header-section-number"
    >10.7</span
    > Summary</a
  ></h2
><div class="footnotes"
><hr
   /><ol
  ><li id="fn1"
    ><p
      >To pass environment variables through remote command dispatches, it is required to properly configure the SSH server on the remote end. See the AcceptEnv directive in the &quot;sshd_config(5)&quot; manual page for instructions. Use a wild card pattern to permit RD_ prefixed variables to provide open access to RunDeck generated environment variables. <a href="#fnref1" class="footnoteBackLink" title="Jump back to footnote 1">↩</a></p
      ></li
    ></ol
  ></div
>
</body>
</html>
